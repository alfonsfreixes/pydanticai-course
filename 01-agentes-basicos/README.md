# MÃ³dulo 1 Â· Agentes Avanzados

**Bienvenido al MÃ³dulo 1.** En el mÃ³dulo anterior aprendiste los fundamentos: configurar agentes, usar tools simples y estructurar salidas. Ahora vamos a profundizar en tÃ©cnicas de producciÃ³n que separan un prototipo de una aplicaciÃ³n empresarial.

En este mÃ³dulo construirÃ¡s agentes que:
- Validan sus propias respuestas antes de devolverlas
- Se autocorrigen cuando detectan errores
- Manejan casos edge de forma elegante
- Integran con sistemas externos de manera controlada

**VersiÃ³n actual:** PydanticAI 1.10+ | Pydantic 2.12 | Python â‰¥3.11

---

## Â¿QuÃ© aprenderÃ¡s en este mÃ³dulo?

Este mÃ³dulo te prepara para construir agentes de nivel empresarial. Los conceptos que cubriremos son los que marcan la diferencia entre "funciona en mi mÃ¡quina" y "funciona en producciÃ³n con miles de usuarios":

**Tools empresariales con validaciÃ³n compleja**  
AprenderÃ¡s a crear funciones que el LLM puede llamar, con validaciÃ³n automÃ¡tica de parÃ¡metros usando Pydantic. VerÃ¡s cÃ³mo manejar mÃºltiples parÃ¡metros, restricciones de negocio y casos edge.

**Output validators para garantizar calidad**  
ImplementarÃ¡s verificaciones que interceptan la respuesta del agente antes de mostrarla al usuario, garantizando que cumple tus estÃ¡ndares de calidad.

**Reflection patterns: el agente se autocorrige**  
El agente revisarÃ¡ su propia salida y la mejorÃ¡ iterativamente, como un editor humano que detecta problemas y reescribe hasta alcanzar calidad profesional.

**Retries inteligentes por criticidad**  
ConfigurarÃ¡s estrategias de reintento diferenciadas: mÃ¡s reintentos para operaciones crÃ­ticas, menos para consultas informativas.

**OrquestaciÃ³n de mÃºltiples tools**  
ConstruirÃ¡s agentes que deciden dinÃ¡micamente quÃ© herramientas usar y en quÃ© orden, sin que tengas que programar el flujo explÃ­citamente.

**Manejo profesional de errores**  
AprenderÃ¡s a construir sistemas que fallan gracefully: nunca exponen stack traces al usuario, siempre devuelven respuestas estructuradas, y escalan a humanos cuando es necesario.

Al final del mÃ³dulo, habrÃ¡s evolucionado el caso de uso DataPulse AI del MÃ³dulo 0 en un sistema con validaciÃ³n, autocorrecciÃ³n y manejo robusto de errores listo para producciÃ³n.

---

## 1. Tools avanzadas con parÃ¡metros complejos

En el MÃ³dulo 0 viste tools simples como `get_current_time()` que no recibÃ­an parÃ¡metros o recibÃ­an uno solo. En producciÃ³n, las tools suelen ser mÃ¡s complejas: mÃºltiples parÃ¡metros, validaciÃ³n de reglas de negocio, manejo de casos edge.

### Â¿Por quÃ© es crÃ­tico validar parÃ¡metros?

Un LLM puede "alucinar" parÃ¡metros invÃ¡lidos. Imagina una tool que consulta una base de datos de clientes:

```python
# âŒ Sin validaciÃ³n
@agent.tool
def get_customer(ctx, customer_id):
    return db.query(f"SELECT * FROM customers WHERE id = {customer_id}")
    # Â¡InyecciÃ³n SQL si el LLM pasa "1 OR 1=1"!
```

Si el LLM decide pasar `"'; DROP TABLE customers; --"` como `customer_id`, tienes un problema grave. La soluciÃ³n: **validaciÃ³n automÃ¡tica con Pydantic**.

```python
# âœ… Con validaciÃ³n Pydantic
@agent.tool
def get_customer(
    ctx,
    customer_id: Annotated[int, Field(gt=0, description="ID del cliente")]
):
    # Si customer_id no es int positivo, Pydantic rechaza antes de ejecutar
    return db.query("SELECT * FROM customers WHERE id = ?", customer_id)
```

**Beneficios de la validaciÃ³n automÃ¡tica:**
- ğŸ›¡ï¸ **Seguridad**: Imposible inyectar SQL o comandos maliciosos
- ğŸ› **Debugging**: Sabes exactamente quÃ© parÃ¡metro era invÃ¡lido y por quÃ©
- ğŸ“š **DocumentaciÃ³n viva**: El schema Pydantic documenta quÃ© valores son vÃ¡lidos
- ğŸ§ª **Testing**: Puedes probar la tool independientemente del agente

### 1.1. Tool con mÃºltiples parÃ¡metros y validaciÃ³n

Vamos a construir un sistema de reporting de ventas empresarial. El agente podrÃ¡ generar reportes filtrando por rango de fechas, regiÃ³n geogrÃ¡fica e importe mÃ­nimo. La tool validarÃ¡ automÃ¡ticamente que:
- Las fechas sean vÃ¡lidas y coherentes (fin > inicio)
- La regiÃ³n sea una de las permitidas
- El importe sea positivo

**Escenario empresarial:**  
Eres el desarrollador de un dashboard de ventas para una empresa internacional. Los managers de diferentes regiones consultan el agente preguntando cosas como: "Â¿CuÃ¡nto facturamos en Europa en enero con pedidos superiores a 1000 EUR?"

**Â¿QuÃ© vamos a construir?**  
Un agente analista de datos que puede responder preguntas complejas sobre ventas, con una tool que valida todos los parÃ¡metros automÃ¡ticamente.

**`01-agentes-avanzados/tool_avanzada.py`:**

```python
from datetime import date
from typing import Annotated, Literal, Dict, Any, List, TypedDict
from pydantic import Field
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.anthropic import AnthropicModel
from pydantic_ai.providers.anthropic import AnthropicProvider
from config import settings

class Transaction(TypedDict):
    date: str
    region: str
    amount: float
    product: str

# Base de datos mock de transacciones
# En producciÃ³n, esto vendrÃ­a de tu base de datos real
MOCK_TRANSACTIONS: List[Transaction] = [
    {"date": "2025-01-05", "region": "EU", "amount": 1250.00, "product": "Laptop Pro"},
    {"date": "2025-01-08", "region": "EU", "amount": 2100.00, "product": "Monitor 4K"},
    {"date": "2025-01-12", "region": "EU", "amount": 890.00, "product": "Mouse Wireless"},
    {"date": "2025-01-15", "region": "EU", "amount": 3400.00, "product": "Laptop Pro"},
    {"date": "2025-01-18", "region": "NA", "amount": 1850.00, "product": "Laptop Pro"},
    {"date": "2025-01-20", "region": "EU", "amount": 1120.00, "product": "Teclado MecÃ¡nico"},
    {"date": "2025-01-22", "region": "LATAM", "amount": 670.00, "product": "Mouse Wireless"},
    {"date": "2025-01-25", "region": "EU", "amount": 4200.00, "product": "Monitor 4K"},
    {"date": "2025-01-28", "region": "APAC", "amount": 2900.00, "product": "Laptop Pro"},
    {"date": "2025-01-30", "region": "EU", "amount": 1560.00, "product": "Laptop Pro"},
]

model = AnthropicModel(
    model_name="claude-sonnet-4-5-20250929",
    provider=AnthropicProvider(api_key=settings.anthropic_api_key)
)

agent = Agent(
    model=model,
    instructions=(
        "Eres un analista de datos empresarial. "
        "Usa la tool de reporting para responder sobre ventas. "
        "Las fechas deben estar en formato YYYY-MM-DD."
    )
)

@agent.tool
async def generate_sales_report(
    ctx: RunContext[None],
    start_date: Annotated[str, Field(description="Fecha inicio en formato YYYY-MM-DD")],
    end_date: Annotated[str, Field(description="Fecha fin en formato YYYY-MM-DD")],
    region: Annotated[
        Literal["EU", "NA", "LATAM", "APAC"],
        Field(description="RegiÃ³n: EU, NA, LATAM o APAC")
    ],
    min_revenue: Annotated[
        float,
        Field(ge=0, description="Filtrar solo pedidos con importe mÃ­nimo en EUR")
    ] = 0.0
) -> Dict[str, Any]:
    """
    Genera un informe de ventas para el perÃ­odo y regiÃ³n especificados.
    
    Filtra transacciones por fecha, regiÃ³n y monto mÃ­nimo, devolviendo
    mÃ©tricas agregadas y los productos mÃ¡s vendidos.
    
    Args:
        start_date: Fecha de inicio del perÃ­odo (YYYY-MM-DD)
        end_date: Fecha de fin del perÃ­odo (YYYY-MM-DD)
        region: RegiÃ³n geogrÃ¡fica (EU, NA, LATAM, APAC)
        min_revenue: Importe mÃ­nimo por transacciÃ³n en EUR (por defecto 0)
        
    Returns:
        Dict con total_revenue, num_transactions, top_products y avg_ticket.
    """
    # Convertir strings a date objects para comparaciÃ³n
    start = date.fromisoformat(start_date)
    end = date.fromisoformat(end_date)
    
    # ValidaciÃ³n de regla de negocio: fechas coherentes
    if end < start:
        return {"error": "La fecha de fin debe ser posterior a la fecha de inicio"}
    
    # Filtrar transacciones segÃºn criterios
    filtered_transactions = [
        t for t in MOCK_TRANSACTIONS
        if (start <= date.fromisoformat(t["date"]) <= end
            and t["region"] == region
            and t["amount"] >= min_revenue)
    ]
    
    # Caso edge: sin resultados
    if not filtered_transactions:
        return {
            "period": f"{start_date} a {end_date}",
            "region": region,
            "total_revenue_eur": 0,
            "num_transactions": 0,
            "top_products": [],
            "avg_ticket_eur": 0,
            "message": "No se encontraron transacciones con los criterios especificados"
        }
    
    # Calcular mÃ©tricas agregadas
    total_revenue = sum(t["amount"] for t in filtered_transactions)
    num_transactions = len(filtered_transactions)
    
    # Top 3 productos mÃ¡s vendidos por cantidad de ventas
    product_count: Dict[str, int] = {}
    for t in filtered_transactions:
        product = t["product"]
        product_count[product] = product_count.get(product, 0) + 1
    
    top_products = sorted(
        product_count.items(),
        key=lambda x: x[1],
        reverse=True
    )[:3]
    
    return {
        "period": f"{start_date} a {end_date}",
        "region": region,
        "total_revenue_eur": round(total_revenue, 2),
        "num_transactions": num_transactions,
        "top_products": [f"{prod} ({count} ventas)" for prod, count in top_products],
        "avg_ticket_eur": round(total_revenue / num_transactions, 2)
    }

# Ejemplos de uso que demuestran diferentes capacidades
print("=== Consulta 1: Todas las ventas de Europa en enero ===")
result1 = agent.run_sync(
    "Â¿CuÃ¡nto facturamos en Europa en enero de 2025?"
)
print(result1.output)

print("\n=== Consulta 2: Ventas en Europa con pedidos >1000 EUR ===")
result2 = agent.run_sync(
    "Â¿CuÃ¡nto facturamos en Europa entre el 1 y 31 de enero de 2025 "
    "con pedidos superiores a 1000 EUR?"
)
print(result2.output)

print("\n=== Consulta 3: Productos mÃ¡s vendidos en Europa ===")
result3 = agent.run_sync(
    "Â¿CuÃ¡les fueron los productos mÃ¡s vendidos en Europa en la segunda quincena de enero de 2025?"
)
print(result3.output)
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/tool_avanzada.py
```

---

### Desglose tÃ©cnico: entendiendo cada pieza

Analicemos en detalle las tÃ©cnicas usadas en este cÃ³digo:

#### 1. Anotaciones con Field()

```python
start_date: Annotated[str, Field(description="Fecha inicio en formato YYYY-MM-DD")]
```

Esta lÃ­nea hace varias cosas a la vez:
- **`str`**: Tipo base del parÃ¡metro
- **`Field(description="...")`**: DocumentaciÃ³n que el LLM lee para entender quÃ© pasar
- **`Annotated[...]`**: Combina el tipo con metadatos de validaciÃ³n

**Â¿Por quÃ© es importante la description?**  
El LLM no "ve" el cÃ³digo Python. Lo que ve es una descripciÃ³n generada automÃ¡ticamente que incluye el docstring y las descriptions de Field. Cuanto mÃ¡s claro escribas, mejor funcionarÃ¡.

#### 2. Literal para valores restringidos

```python
region: Annotated[
    Literal["EU", "NA", "LATAM", "APAC"],
    Field(description="RegiÃ³n: EU, NA, LATAM o APAC")
]
```

`Literal` es una restricciÃ³n fuerte: el LLM **solo puede pasar** uno de esos valores exactos. Si intenta pasar "Europe" o "Europa", Pydantic rechaza la llamada antes de que tu cÃ³digo se ejecute.

**En producciÃ³n:**
```python
# Si tu DB tiene 50 regiones, puedes generarlo dinÃ¡micamente:
VALID_REGIONS = ["EU", "NA", "LATAM", "APAC", ...]
RegionType = Literal[*VALID_REGIONS]

region: Annotated[RegionType, Field(description="...")]
```

#### 3. Constraints numÃ©ricos

```python
min_revenue: Annotated[
    float,
    Field(ge=0, description="Filtrar solo pedidos con importe mÃ­nimo en EUR")
] = 0.0
```

- **`ge=0`**: "greater or equal than 0" - no acepta negativos
- **`= 0.0`**: Valor por defecto si no se especifica
- TambiÃ©n disponibles: `gt`, `le`, `lt`, `multiple_of`, etc.

```python
# Otros ejemplos Ãºtiles:
edad: Annotated[int, Field(ge=18, le=120)]  # Entre 18 y 120
precio: Annotated[float, Field(gt=0, multiple_of=0.01)]  # Positivo, 2 decimales
codigo: Annotated[str, Field(pattern=r"^[A-Z]{3}-\d{4}$")]  # ABC-1234
```

#### 4. Docstring estructurado

El docstring es **crÃ­tico** porque el LLM lo lee para decidir:
- CuÃ¡ndo usar esta tool vs otras disponibles
- QuÃ© valores pasar en cada parÃ¡metro
- QuÃ© esperar como respuesta

**Estructura recomendada:**
```python
"""
[Resumen en 1 lÃ­nea de quÃ© hace]

[PÃ¡rrafo explicativo opcional]

Args:
    param1: QuÃ© es y formato esperado
    param2: QuÃ© es y formato esperado

Returns:
    QuÃ© estructura devuelve y quÃ© campos contiene
"""
```

#### 5. ValidaciÃ³n en capas

Este cÃ³digo implementa validaciÃ³n en **tres niveles**:

**Nivel 1: Pydantic (automÃ¡tico)**
```python
# Rechaza si region no estÃ¡ en Literal
# Rechaza si min_revenue < 0
# Rechaza si start_date no es string
```

**Nivel 2: LÃ³gica de negocio (manual)**
```python
if end < start:
    return {"error": "..."}
```

**Nivel 3: Casos edge (defensivo)**
```python
if not filtered_transactions:
    return {"message": "Sin resultados", ...}
```

Esta arquitectura garantiza que:
- Errores de tipo se capturan antes de ejecutar
- Reglas de negocio se validan explÃ­citamente
- Casos sin datos se manejan elegantemente

#### 6. Datos mock realistas

Los datos de ejemplo no son triviales. Incluyen:
- Fechas distribuidas en enero
- MÃºltiples regiones
- Variedad de productos y precios
- Permite probar diferentes queries

**En producciÃ³n:**
```python
# Reemplazas MOCK_TRANSACTIONS con:
filtered_transactions = db.execute(
    """
    SELECT date, region, amount, product
    FROM transactions
    WHERE date BETWEEN ? AND ?
      AND region = ?
      AND amount >= ?
    """,
    (start_date, end_date, region, min_revenue)
).fetchall()
```

---

### ComparaciÃ³n: Sin validaciÃ³n vs Con validaciÃ³n

**Sin validaciÃ³n (âŒ Peligroso):**
```python
@agent.tool
def get_sales(ctx, start, end, region, min_amount):
    # Â¿QuÃ© pasa si start no es fecha vÃ¡lida?
    # Â¿QuÃ© pasa si region = "'; DROP TABLE sales; --"?
    # Â¿QuÃ© pasa si min_amount = -999999?
    query = f"SELECT * FROM sales WHERE date >= '{start}' ..."
    # Â¡MÃºltiples vectores de ataque!
```

**Con validaciÃ³n (âœ… Seguro):**
```python
@agent.tool
async def get_sales(
    ctx,
    start: Annotated[str, Field(pattern=r"^\d{4}-\d{2}-\d{2}$")],
    end: Annotated[str, Field(pattern=r"^\d{4}-\d{2}-\d{2}$")],
    region: Literal["EU", "NA", "LATAM", "APAC"],
    min_amount: Annotated[float, Field(ge=0)]
):
    # Si llega aquÃ­, los parÃ¡metros son vÃ¡lidos por definiciÃ³n
    query = "SELECT * FROM sales WHERE date >= ? ..."  # Prepared statement
```

---

### Mejores prÃ¡cticas para tools complejas

**1. ParÃ¡metros individuales, no dicts**

```python
# âŒ Malo: difÃ­cil de validar
@agent.tool
def process(ctx, data: dict):
    # Â¿QuÃ© claves tiene data? Â¿QuÃ© tipos?
    pass

# âœ… Bueno: cada parÃ¡metro validado
@agent.tool
def process(
    ctx,
    customer_id: Annotated[int, Field(gt=0)],
    amount: Annotated[float, Field(ge=0)],
    currency: Literal["EUR", "USD"]
):
    pass
```

**2. Valores por defecto sensatos**

```python
# âœ… Bueno: defaults que cubren el 80% de casos
@agent.tool
def search_products(
    ctx,
    query: str,
    max_results: Annotated[int, Field(ge=1, le=100)] = 10,  # Por defecto 10
    include_discontinued: bool = False  # Por defecto excluye
):
    pass
```

**3. Descriptions que guÃ­an al LLM**

```python
# âŒ Malo: descripciÃ³n vaga
date: Annotated[str, Field(description="A date")]

# âœ… Bueno: descripciÃ³n con formato y ejemplos
date: Annotated[
    str,
    Field(description="Fecha en formato YYYY-MM-DD (ej: 2025-01-15)")
]
```

**4. Manejo explÃ­cito de casos sin resultados**

```python
# âŒ Malo: devuelve lista vacÃ­a
if not results:
    return []

# âœ… Bueno: devuelve dict estructurado con mensaje
if not results:
    return {
        "found": False,
        "message": "No se encontraron productos que coincidan",
        "suggestions": ["Prueba tÃ©rminos mÃ¡s generales", ...]
    }
```

---

### 1.2. MÃºltiples tools y orquestaciÃ³n

En sistemas reales, un agente suele necesitar acceso a varias herramientas diferentes. El LLM decide automÃ¡ticamente **cuÃ¡l usar, cuÃ¡ndo y en quÃ© orden** segÃºn el contexto de la pregunta del usuario.

**Â¿Por quÃ© es revolucionario?**  
Con enfoques tradicionales (if/else, regex), debes programar explÃ­citamente cada flujo posible. Con PydanticAI, describes las tools disponibles y el LLM orquesta el flujo dinÃ¡micamente.

```python
# Enfoque tradicional âŒ
if "stock" in query and "pedido" in query:
    result1 = check_stock()
    result2 = track_order()
    return combine(result1, result2)
elif "stock" in query:
    return check_stock()
elif "pedido" in query:
    return track_order()
# ... decenas de combinaciones mÃ¡s

# Enfoque PydanticAI âœ…
result = agent.run_sync(query)
# El agente decide quÃ© tools llamar y en quÃ© orden
```

**Escenario empresarial:**  
Imagina un asistente de e-commerce. Los clientes hacen preguntas como:
- "Â¿TenÃ©is el Mouse Wireless?" â†’ necesita buscar producto y consultar stock
- "Â¿DÃ³nde estÃ¡ mi pedido ORD-1002?" â†’ necesita rastrear pedido
- "Quiero un Monitor 4K, Â¿hay stock? Y revisa mi pedido ORD-1001" â†’ necesita ambas tools

No quieres un agente diferente para cada caso. Quieres **un agente que sepa quÃ© hacer**.

**Â¿QuÃ© vamos a construir?**  
Un asistente que puede:
- Buscar productos por nombre
- Consultar stock con cÃ³digo de producto
- Rastrear estado de pedidos
- Combinar resultados cuando sea necesario

**`01-agentes-avanzados/multi_tools.py`:**

```python
from pydantic import BaseModel
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings
from typing import Dict, Any
from enum import Enum

class OrderStatus(str, Enum):
    """Estados posibles de un pedido."""
    PROCESSING = "processing"  # En preparaciÃ³n
    READY_TO_SHIP = "ready_to_ship"  # Listo para enviar
    SHIPPED = "shipped"  # Enviado
    DELIVERED = "delivered"  # Entregado
    CANCELLED = "cancelled"  # Cancelado

class Product(BaseModel):
    name: str
    stock: int
    price_eur: float

class Order(BaseModel):
    product_code: str
    quantity: int
    status: OrderStatus
    estimated_delivery_days: int | None = None

# SimulaciÃ³n de sistemas empresariales
INVENTORY: Dict[str, Product] = {
    "P001": Product(name="Laptop Pro", stock=45, price_eur=1299.00),
    "P002": Product(name="Mouse Wireless", stock=0, price_eur=29.99),
    "P003": Product(name="Monitor 4K", stock=12, price_eur=449.00),
}

ORDERS_DB: Dict[str, Order] = {
    "ORD-1001": Order(
        product_code="P001",
        quantity=2,
        status=OrderStatus.SHIPPED,
        estimated_delivery_days=2
    ),
    "ORD-1002": Order(
        product_code="P003",
        quantity=1,
        status=OrderStatus.PROCESSING,
        estimated_delivery_days=3
    ),
}

# Mapeo de estados a descripciones claras
STATUS_DESCRIPTIONS = {
    OrderStatus.PROCESSING: "En preparaciÃ³n en almacÃ©n",
    OrderStatus.READY_TO_SHIP: "Preparado, pendiente de recogida por transportista",
    OrderStatus.SHIPPED: "En trÃ¡nsito",
    OrderStatus.DELIVERED: "Entregado",
    OrderStatus.CANCELLED: "Cancelado",
}

model = OpenAIChatModel(
    model_name="gpt-5-mini",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model=model,
    instructions=(
        "Eres un asistente de e-commerce profesional y conciso. "
        "Responde consultas sobre inventario y pedidos de forma directa y clara.\n\n"
        "IMPORTANTE:\n"
        "- Proporciona la informaciÃ³n solicitada de forma directa\n"
        "- NO hagas preguntas adicionales ni ofrezcas opciones extras\n"
        "- Usa lenguaje ejecutivo y profesional\n"
        "- Si el usuario menciona un nombre de producto, usa search_product primero\n"
        "- SÃ© conciso: mÃ¡ximo 2-3 frases por respuesta"
    )
)

@agent.tool
def search_product(ctx: RunContext[None], query: str) -> Dict[str, Any]:
    """
    Busca productos por nombre o descripciÃ³n.
    
    Usa esta funciÃ³n cuando el usuario mencione un producto por su nombre
    (ej: "Mouse Wireless", "Laptop") pero NO cuando mencione un cÃ³digo (ej: P001).
    
    Args:
        query: Nombre o parte del nombre del producto a buscar.
        
    Returns:
        Dict con lista de productos que coinciden con la bÃºsqueda.
    """
    query_lower = query.lower()
    matches: list[Dict[str, Any]] = [
        {
            "product_code": code,
            "name": product.name,
            "match_score": 1.0 if query_lower in product.name.lower() else 0.5
        }
        for code, product in INVENTORY.items()
        if query_lower in product.name.lower()
    ]
    
    if not matches:
        return {
            "found": False,
            "message": f"No se encontraron productos que coincidan con '{query}'",
            "available_products": [
                {"code": code, "name": product.name}
                for code, product in INVENTORY.items()
            ]
        }
    
    return {
        "found": True,
        "matches": matches,
        "message": f"Se encontraron {len(matches)} productos"
    }

@agent.tool
def check_stock(ctx: RunContext[None], product_code: str) -> Dict[str, Any]:
    """
    Consulta el stock actual de un producto por su cÃ³digo.
    
    Usa esta funciÃ³n cuando tengas el cÃ³digo del producto (formato PXXX).
    Si solo tienes el nombre, usa search_product primero.
    
    Args:
        product_code: CÃ³digo Ãºnico del producto (ej: P001, P002, P003).
        
    Returns:
        Dict con informaciÃ³n detallada del producto y disponibilidad.
    """
    product = INVENTORY.get(product_code)
    if not product:
        return {"error": f"Producto {product_code} no encontrado"}
    
    return {
        "product_code": product_code,
        "name": product.name,
        "stock_units": product.stock,
        "price_eur": product.price_eur,
        "available": product.stock > 0,
        "status_message": (
            f"Disponible ({product.stock} unidades)" 
            if product.stock > 0 
            else "Agotado"
        )
    }

@agent.tool
def track_order(ctx: RunContext[None], order_id: str) -> Dict[str, Any]:
    """
    Rastrea el estado de un pedido por su ID.
    
    Usa esta funciÃ³n cuando el usuario pregunte sobre el estado,
    seguimiento o ubicaciÃ³n de un pedido especÃ­fico.
    
    Args:
        order_id: ID del pedido en formato ORD-XXXX (ej: ORD-1001).
        
    Returns:
        Dict con detalles del pedido, estado actual y tiempo estimado de entrega.
    """
    order = ORDERS_DB.get(order_id)
    if not order:
        return {"error": f"Pedido {order_id} no encontrado"}
    
    product = INVENTORY.get(order.product_code)
    status_desc = STATUS_DESCRIPTIONS.get(order.status, "Estado desconocido")
    
    result: Dict[str, Any] = {
        "order_id": order_id,
        "product_name": product.name if product else "Unknown",
        "quantity": order.quantity,
        "status": order.status.value,
        "status_description": status_desc,
    }
    
    # Agregar informaciÃ³n de entrega solo si estÃ¡ disponible
    if order.estimated_delivery_days:
        result["estimated_delivery"] = f"{order.estimated_delivery_days} dÃ­as hÃ¡biles"
    
    return result

# Pruebas que demuestran las mejoras
consulta: str = "Â¿TenÃ©is disponible el Mouse Wireless?"
print("=== Consulta 1: Respuesta directa sin preguntas adicionales ===\n")
print(consulta)

r1 = agent.run_sync(consulta)
print(r1.output)

consulta2: str = "Â¿CuÃ¡l es el estado de mi pedido ORD-1002?"
print("\n=== Consulta 2: Estado claro y tiempo estimado ===\n") 
print(consulta2)
r2 = agent.run_sync(consulta2)
print(r2.output)

consulta3: str = "Quiero comprar un Monitor 4K, Â¿hay stock? Y de paso revisa el pedido ORD-1001"
print("\n=== Consulta 3: InformaciÃ³n completa y concisa ===\n")
print(consulta3)
r3 = agent.run_sync(consulta3)
print(r3.output)
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/multi_tools.py
```

---

### CÃ³mo funciona la orquestaciÃ³n automÃ¡tica

Cuando ejecutas `agent.run_sync("Â¿TenÃ©is Mouse Wireless?")`, esto es lo que pasa internamente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Usuario: "Â¿TenÃ©is Mouse Wireless?"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Agente analiza la consulta               â”‚
â”‚    - Detecta: producto mencionado (nombre)  â”‚
â”‚    - Detecta: consulta sobre disponibilidad â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Agente lee docstrings de tools           â”‚
â”‚    search_product: "cuando usuario mencione â”‚
â”‚                     nombre (ej: Mouse)"     â”‚
â”‚    check_stock: "cuando tengas cÃ³digo PXXX" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Agente decide: usar search_product       â”‚
â”‚    Llama: search_product("Mouse Wireless")  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Tool devuelve: {product_code: "P002"}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Agente: "Tengo cÃ³digo, ahora necesito    â”‚
â”‚    stock". Llama: check_stock("P002")       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Tool devuelve: {stock: 0, available: F}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Agente genera respuesta natural:         â”‚
â”‚    "El Mouse Wireless (cÃ³digo P002) estÃ¡    â”‚
â”‚    agotado; stock 0 unidades."              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Lo revolucionario:** No programaste este flujo. Solo describiste las tools disponibles y el agente decidiÃ³:
1. QuÃ© tools usar
2. En quÃ© orden
3. CÃ³mo combinar los resultados

---

### AnÃ¡lisis de las tres consultas de prueba

#### Consulta 1: "Â¿TenÃ©is disponible el Mouse Wireless?"

**Flujo automÃ¡tico (2 tools):**
```
Usuario menciona: "Mouse Wireless" (nombre, no cÃ³digo)
    â†“
Tool 1: search_product("Mouse Wireless")
    â†’ Resultado: {"product_code": "P002"}
    â†“
Tool 2: check_stock("P002")
    â†’ Resultado: {"stock_units": 0, "status": "Agotado"}
    â†“
Respuesta: "El Mouse Wireless (cÃ³digo P002) estÃ¡ agotado; stock 0 unidades."
```

**El agente aprendiÃ³ solo** que debe buscar el cÃ³digo primero cuando el usuario menciona un nombre. Esto estÃ¡ guiado por los docstrings:
- `search_product`: "cuando usuario mencione nombre"
- `check_stock`: "cuando tengas cÃ³digo"

#### Consulta 2: "Â¿CuÃ¡l es el estado de mi pedido ORD-1002?"

**Flujo simple (1 tool):**
```
Usuario menciona: ID de pedido directo
    â†“
Tool: track_order("ORD-1002")
    â†’ Resultado: {
        "status_description": "En preparaciÃ³n en almacÃ©n",
        "estimated_delivery": "3 dÃ­as hÃ¡biles"
    }
    â†“
Respuesta: "Tu pedido ORD-1002 (Monitor 4K x1) estÃ¡ en preparaciÃ³n 
            en almacÃ©n. Entrega estimada: 3 dÃ­as hÃ¡biles."
```

**DiseÃ±o de estados profesional:**
- âŒ Malo: `"status": "pending"` â†’ ambiguo para el cliente
- âœ… Bueno: `"status_description": "En preparaciÃ³n en almacÃ©n"` â†’ claro

#### Consulta 3: "Quiero Monitor 4K, Â¿hay stock? Revisa pedido ORD-1001"

**Flujo complejo (3 tools, 2 intenciones):**
```
El agente detecta DOS consultas independientes
    â†“
IntenciÃ³n 1: Stock de Monitor 4K
    Tool 1: search_product("Monitor 4K") â†’ P003
    Tool 2: check_stock("P003") â†’ 12 unidades, 449 EUR
    â†“
IntenciÃ³n 2: Estado del pedido
    Tool 3: track_order("ORD-1001") â†’ Enviado, 2 dÃ­as
    â†“
Respuesta: "Monitor 4K (cÃ³digo P003): disponible, 12 unidades a 449â‚¬.
            Tu pedido ORD-1001 estÃ¡ en trÃ¡nsito, llegarÃ¡ en 2 dÃ­as."
```

**Esto demuestra:**
- Identificar mÃºltiples intenciones en una pregunta
- Ejecutar tools en orden lÃ³gico correcto
- Sintetizar resultados sin perder informaciÃ³n clave

---

### Control del tono conversacional

**Problema comÃºn:** Sin instrucciones explÃ­citas, los LLMs son excesivamente conversacionales:

```
âŒ Sin control de tono:
"Â¡Hola! Claro que sÃ­, el Mouse Wireless... oh no, vaya, parece que 
estÃ¡ agotado ğŸ˜”. Pero no te preocupes, Â¿te gustarÃ­a que:
1. Te avise cuando se reponga?
2. Busque alternativas similares?
3. Te muestre otros productos?"
```

```
âœ… Con control de tono:
"El Mouse Wireless (cÃ³digo P002) estÃ¡ agotado; stock 0 unidades."
```

**SoluciÃ³n implementada en las instrucciones:**
```python
instructions=(
    "Eres un asistente de e-commerce profesional y conciso.\n\n"
    "IMPORTANTE:\n"
    "- Proporciona la informaciÃ³n de forma directa\n"
    "- NO hagas preguntas adicionales\n"
    "- MÃ¡ximo 2-3 frases por respuesta"
)
```

**Claves para control de tono:**
- Usar **MAYÃšSCULAS** para Ã©nfasis en lo crÃ­tico
- Establecer **lÃ­mites concretos** (mÃ¡ximo 2-3 frases)
- **Prohibir explÃ­citamente** comportamientos no deseados (NO hagas preguntas)
- Pedir estilo especÃ­fico (profesional, conciso, ejecutivo)

---

### ComparaciÃ³n: Arquitectura tradicional vs PydanticAI

**Enfoque tradicional (rÃ­gido):**
```python
def handle_query(query):
    # Necesitas anticipar TODAS las combinaciones
    if "stock" in query and "pedido" in query:
        result1 = check_stock()
        result2 = track_order()
        return combine(result1, result2)
    elif "stock" in query:
        return check_stock()
    elif "pedido" in query:
        return track_order()
    # âŒ No maneja:
    # - SinÃ³nimos (disponibilidad, existencias)
    # - ParÃ¡frasis (Â¿tienen X?, Â¿queda X?, Â¿hay X?)
    # - Nuevas combinaciones
```

**Enfoque PydanticAI (flexible):**
```python
# Defines las tools disponibles
@agent.tool
def search_product(...): pass

@agent.tool
def check_stock(...): pass

@agent.tool
def track_order(...): pass

# El agente decide dinÃ¡micamente
result = agent.run_sync(query)
# âœ… Maneja:
# - Cualquier forma de preguntar
# - Nuevas combinaciones
# - MÃºltiples idiomas
# - Contexto implÃ­cito
```

---

### Buenas prÃ¡cticas para multi-tool systems

**1. Docstrings que guÃ­an la selecciÃ³n**

```python
# âœ… Bueno: explica cuÃ¡ndo usar cada tool
@agent.tool
def search_product(ctx, query: str):
    """
    Busca productos por nombre.
    
    Ãšsala cuando el usuario mencione un producto por su nombre
    (ej: "Mouse Wireless") pero NO cuando mencione un cÃ³digo (ej: P001).
    """
    pass

@agent.tool
def check_stock(ctx, product_code: str):
    """
    Consulta stock por cÃ³digo de producto.
    
    Ãšsala cuando tengas el cÃ³digo del producto (formato PXXX).
    Si solo tienes el nombre, usa search_product primero.
    """
    pass
```

**2. SeparaciÃ³n clara de responsabilidades**

```python
# âœ… Bueno: cada tool hace UNA cosa
search_product()  # Solo busca cÃ³digos por nombre
check_stock()     # Solo consulta stock con cÃ³digo conocido
track_order()     # Solo rastrea pedidos

# âŒ Malo: tool que hace demasiado
get_product_info()  # Â¿Busca? Â¿Consulta stock? Â¿Ambos? Â¿CuÃ¡ndo?
```

**3. Respuestas estructuradas consistentes**

```python
# âœ… Todas las tools devuelven dicts con estructura similar
{
    "success": bool,
    "data": {...},
    "message": str | None,
    "error": str | None
}

# Facilita que el agente combine resultados
```

**4. Estados descriptivos para usuarios finales**

```python
# âŒ Malo: cÃ³digos tÃ©cnicos
OrderStatus.PENDING

# âœ… Bueno: descripciones claras
STATUS_DESCRIPTIONS = {
    OrderStatus.PENDING: "En preparaciÃ³n en almacÃ©n",
    OrderStatus.SHIPPED: "En trÃ¡nsito",
}
```

---

### Escalabilidad: de 3 a 30 tools

El mismo patrÃ³n escala linealmente:

```python
agent = Agent(model)

# Tools de inventario
@agent.tool
def search_products(...): pass

@agent.tool
def check_stock(...): pass

@agent.tool
def reserve_stock(...): pass

# Tools de pedidos
@agent.tool
def create_order(...): pass

@agent.tool
def track_order(...): pass

@agent.tool
def cancel_order(...): pass

# Tools de clientes
@agent.tool
def get_customer_info(...): pass

@agent.tool
def update_preferences(...): pass

# Tools de pagos
@agent.tool
def process_payment(...): pass

@agent.tool
def issue_refund(...): pass

# ... hasta 30+ tools
```

**El agente seguirÃ¡ orquestando correctamente** mientras cada tool tenga:
- Docstring claro que explica cuÃ¡ndo usarla
- ParÃ¡metros bien validados
- Responsabilidad Ãºnica y bien definida

---

## 2. Output Validators y Reflection

Hasta ahora, el agente genera una respuesta y la devuelve al usuario inmediatamente. Pero, Â¿quÃ© pasa si la respuesta es demasiado vaga, contiene errores lÃ³gicos, o contradice tus reglas de negocio?

Los **output validators** (`@agent.output_validator`) te permiten interceptar la respuesta **antes** de que llegue al usuario, verificarla segÃºn tus criterios, y si no los cumple, hacer que el agente la regenere automÃ¡ticamente mediante `ModelRetry`.

### Â¿Por quÃ© es revolucionario?

Es como tener un **editor automÃ¡tico de calidad** que revisa todo lo que escribe el modelo antes de publicarlo. No confÃ­as ciegamente en el LLM; verificas su trabajo y lo obligas a mejorarlo hasta que cumpla tus estÃ¡ndares.

**Sin validator:**
```
Usuario: "Genera propuesta para DataPulse"
Agente: "DataPulse es una soluciÃ³n innovadora lÃ­der del mercado..."
â†’ Se envÃ­a al usuario (con frases vacÃ­as)
```

**Con validator:**
```
Usuario: "Genera propuesta para DataPulse"
Intento 1: "DataPulse es una soluciÃ³n innovadora..."
Validator: âŒ "Elimina frases genÃ©ricas"
Intento 2: "DataPulse automatiza anÃ¡lisis empresarial con ROI del 300%..."
Validator: âœ… Aprobado
â†’ Se envÃ­a al usuario (con datos concretos)
```

### 2.1. ValidaciÃ³n bÃ¡sica con ModelRetry

Vamos a construir un generador de **propuestas comerciales** para un equipo de ventas. Queremos garantizar que cada propuesta cumpla estÃ¡ndares profesionales antes de enviarse al cliente.

**Escenario empresarial:**  
Trabajas en una consultora que envÃ­a decenas de propuestas semanalmente. El equipo comercial se queja de que a veces el agente genera:
- TÃ­tulos genÃ©ricos que no mencionan al cliente
- Lenguaje de brochure vacÃ­o ("soluciÃ³n innovadora", "lÃ­der del mercado")
- Beneficios vagos sin datos concretos
- Presupuestos incoherentes con el brief

Necesitas un sistema que **garantice calidad** antes de que la propuesta llegue al cliente.

**Â¿QuÃ© vamos a construir?**  
Un sistema que genera propuestas y las valida automÃ¡ticamente segÃºn 4 criterios empresariales:
1. TÃ­tulo debe mencionar al cliente
2. Resumen sin frases genÃ©ricas
3. Beneficios desarrollados (mÃ­nimo 8 palabras)
4. Presupuesto coherente (Â±20% del brief)

**`01-agentes-avanzados/result_validation.py`:**

```python
from __future__ import annotations

from typing import Optional

from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.models.anthropic import AnthropicModel
from pydantic_ai.providers.anthropic import AnthropicProvider

from config import settings

class SalesProposal(BaseModel):
    """Propuesta comercial estructurada."""
    client_name: str = Field(min_length=3, description="Nombre del cliente")
    proposal_title: str = Field(min_length=10, max_length=100)
    budget_eur: Optional[float] = Field(default=None, gt=0, description="Presupuesto del brief si estÃ¡ disponible")
    estimated_value_eur: float = Field(gt=0, le=1_000_000)
    executive_summary: str = Field(min_length=50, max_length=300)
    key_benefits: list[str] = Field(min_length=3, max_length=5)

model = AnthropicModel(
    model_name="claude-sonnet-4-5-20250929",
    provider=AnthropicProvider(api_key=settings.anthropic_api_key),
)

MAX_RETRIES = 2

agent = Agent(
    model=model,
    output_type=SalesProposal,
    retries=MAX_RETRIES,
    instructions=(
        "Eres un consultor comercial que crea propuestas de valor para clientes B2B. "
        "Devuelve *exclusivamente* un objeto vÃ¡lido del tipo SalesProposal. "
        "Escribe en espaÃ±ol, tono ejecutivo y concreto. Evita jerga y frases vacÃ­as. "
        "Si el brief trae presupuesto, rellena el campo 'budget_eur' con esa cifra exacta. "
        "Procura que 'estimated_value_eur' sea coherente con 'budget_eur' (si existe). "
        "Incluye beneficios especÃ­ficos y, cuando proceda, cuantifÃ­calos."
    ),
)

@agent.output_validator
async def validate_proposal_quality(
    ctx: RunContext[None],
    result: SalesProposal
) -> SalesProposal:
    """
    Valida la calidad de la propuesta comercial.
    Lanza ModelRetry con feedback accionable si detecta problemas.
    """
    # --------- ValidaciÃ³n 1: TÃ­tulo debe mencionar al cliente ---------
    if result.client_name.lower() not in result.proposal_title.lower():
        raise ModelRetry(
            f"El tÃ­tulo debe mencionar explÃ­citamente al cliente '{result.client_name}'. "
            f"TÃ­tulo actual: '{result.proposal_title}'. Reescribe el tÃ­tulo incluyendo el nombre del cliente."
        )

    # --------- ValidaciÃ³n 2: Evitar resÃºmenes genÃ©ricos ---------
    summary_lc = result.executive_summary.lower()
    generic_phrases = {
        "soluciÃ³n innovadora",
        "la mejor opciÃ³n",
        "excelente oportunidad",
        "lÃ­der del mercado",
        "state of the art",
        "mejores prÃ¡cticas",
        "gran impacto",
        "resultados sin precedentes",
        "alto valor aÃ±adido",
    }
    if any(p in summary_lc for p in generic_phrases):
        raise ModelRetry(
            "El resumen ejecutivo contiene frases genÃ©ricas. "
            "Sustituye por lenguaje especÃ­fico con datos concretos, mÃ©tricas estimadas y supuestos claros."
        )

    # --------- ValidaciÃ³n 3: Beneficios con sustancia (â‰¥ 8 palabras) ---------
    short_benefits = [b for b in result.key_benefits if len(b.split()) < 8]
    if short_benefits:
        raise ModelRetry(
            f"Los siguientes beneficios son demasiado vagos: {short_benefits}. "
            "Desarrolla cada beneficio con al menos 8 palabras, con verbos de acciÃ³n y, si procede, mÃ©tricas estimadas."
        )

    # --------- ValidaciÃ³n 4: Coherencia presupuesto vs estimaciÃ³n (simple y explÃ­cita) ---------
    # Si budget_eur viene informado, pedimos que estimated_value_eur no se desvÃ­e >Â±20%
    if result.budget_eur is not None and result.budget_eur > 0:
        lower = 0.8 * result.budget_eur
        upper = 1.2 * result.budget_eur
        if not (lower <= result.estimated_value_eur <= upper):
            raise ModelRetry(
                f"El valor estimado ({result.estimated_value_eur:,.0f} EUR) no es coherente con el presupuesto "
                f"({result.budget_eur:,.0f} EUR). Ajusta la cifra o justifica brevemente (1-2 frases) la desviaciÃ³n."
            )

    return result

def run_example() -> None:
    prompt = (
        "Crea una propuesta para DataPulse para implementar un sistema de IA de anÃ¡lisis de datos. "
        "Presupuesto estimado: 35.000 EUR. Entregables: pipeline de ingesta, dashboard ejecutivo y "
        "automatizaciÃ³n de informes semanales."
    )

    try:
        result = agent.run_sync(prompt)
        proposal = result.output

        print("=" * 80)
        print(f"Cliente : {proposal.client_name}")
        print(f"TÃ­tulo  : {proposal.proposal_title}")
        if proposal.budget_eur is not None:
            print(f"Presupuesto (brief): {proposal.budget_eur:,.2f} EUR".replace(",", "X").replace(".", ",").replace("X", "."))
        print(f"Valor estimado     : {proposal.estimated_value_eur:,.2f} EUR".replace(",", "X").replace(".", ",").replace("X", "."))
        print("-" * 80)
        print("Resumen Ejecutivo:\n")
        print(proposal.executive_summary)
        print("\nBeneficios Clave:")
        for i, benefit in enumerate(proposal.key_benefits, 1):
            print(f"  {i}. {benefit}")
        print("=" * 80)

    except Exception as e:
        print(f"Error tras {MAX_RETRIES} intentos: {e}")


if __name__ == "__main__":
    run_example()
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/result_validation.py
```

---

### Entendiendo el flujo de validaciÃ³n

Cuando ejecutas este cÃ³digo, el validator intercepta la respuesta antes de que llegue al usuario:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Agente genera propuesta inicial             â”‚
â”‚    (puede contener problemas de calidad)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Validator revisa los 4 criterios            â”‚
â”‚    - Cliente en tÃ­tulo?                        â”‚
â”‚    - Sin frases genÃ©ricas?                     â”‚
â”‚    - Beneficios desarrollados?                 â”‚
â”‚    - Presupuesto coherente?                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
            Â¿Alguno falla?
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
       SÃ                      NO
        â”‚                       â”‚
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ModelRetry    â”‚      â”‚ Devuelve      â”‚
â”‚ con feedback  â”‚      â”‚ al usuario    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Agente lee el feedback y regenera           â”‚
â”‚    "Ah, debo mencionar DataPulse en tÃ­tulo"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Validator revisa nuevamente                 â”‚
â”‚    (repite hasta pasar o agotar MAX_RETRIES)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Las 4 validaciones empresariales explicadas

#### ValidaciÃ³n 1: Cliente en el tÃ­tulo

```python
if result.client_name.lower() not in result.proposal_title.lower():
    raise ModelRetry(
        f"El tÃ­tulo debe mencionar explÃ­citamente al cliente '{result.client_name}'..."
    )
```

**Â¿Por quÃ© es importante?**  
Los tÃ­tulos genÃ©ricos tipo "Propuesta de IA para anÃ¡lisis empresarial" no personalizan. El cliente quiere ver su nombre: "Sistema de AnÃ¡lisis IA para DataPulse".

**Ejemplo de iteraciÃ³n:**
```
Intento 1: "Propuesta de IA para anÃ¡lisis empresarial"
âŒ Validator: "Debe mencionar 'DataPulse'"

Intento 2: "Sistema de AnÃ¡lisis IA para DataPulse"
âœ… Aprobado
```

#### ValidaciÃ³n 2: Lenguaje concreto (no brochure)

```python
generic_phrases = {
    "soluciÃ³n innovadora",
    "lÃ­der del mercado",
    "alto valor aÃ±adido",
    ...
}
if any(p in summary_lc for p in generic_phrases):
    raise ModelRetry("Sustituye por lenguaje especÃ­fico con datos concretos...")
```

**Â¿Por quÃ© es crÃ­tico?**  
Las frases de marketing vacÃ­o no convencen a ejecutivos. Necesitan datos: "Pipeline ML procesando 50k registros/dÃ­a con reducciÃ³n estimada de 15h/semana en anÃ¡lisis manual" es mucho mÃ¡s potente que "soluciÃ³n innovadora de alto valor".

**Ejemplo de iteraciÃ³n:**
```
Intento 1: "DataPulse es una soluciÃ³n innovadora que transformarÃ¡..."
âŒ Validator: "Elimina frases genÃ©ricas"

Intento 2: "Pipeline procesando 50k registros/dÃ­a, reduciendo 15h/semana 
            de anÃ¡lisis manual mediante modelos ML predictivos..."
âœ… Aprobado
```

#### ValidaciÃ³n 3: Beneficios desarrollados (â‰¥8 palabras)

```python
short_benefits = [b for b in result.key_benefits if len(b.split()) < 8]
if short_benefits:
    raise ModelRetry("Desarrolla cada beneficio con al menos 8 palabras...")
```

**Â¿Por quÃ© 8 palabras?**  
Los beneficios vagos tipo "ROI positivo" o "Mejor anÃ¡lisis" no dan informaciÃ³n Ãºtil. Un beneficio desarrollado explica el quÃ©, el cÃ³mo y el impacto: "ReducciÃ³n del 40% en tiempo de generaciÃ³n de reportes mediante automatizaciÃ³n de pipelines de datos" (14 palabras).

**Ejemplo de iteraciÃ³n:**
```
Intento 1: ["ROI positivo", "Mejor anÃ¡lisis", "Datos claros"]
âŒ Validator: "Beneficios demasiado vagos (<8 palabras)"

Intento 2: [
    "ReducciÃ³n del 40% en tiempo de reportes mediante automatizaciÃ³n",
    "Dashboard ejecutivo con 15 KPIs actualizados en tiempo real",
    "Alertas predictivas que identifican tendencias 3 semanas antes"
]
âœ… Aprobado (cada uno >8 palabras, con datos especÃ­ficos)
```

#### ValidaciÃ³n 4: Coherencia presupuesto Â±20%

```python
if result.budget_eur is not None:
    lower = 0.8 * result.budget_eur
    upper = 1.2 * result.budget_eur
    if not (lower <= result.estimated_value_eur <= upper):
        raise ModelRetry(
            f"Valor estimado ({result.estimated_value_eur}) no coherente 
            con presupuesto ({result.budget_eur})..."
        )
```

**Â¿Por quÃ© Â±20%?**  
Si el cliente menciona presupuesto de 35k EUR y tu propuesta estima 80k EUR, hay desconexiÃ³n. El validator exige coherencia: entre 28k-42k EUR (Â±20%).

**Ejemplo de iteraciÃ³n:**
```
Brief: presupuesto 35.000 EUR

Intento 1: estimated_value_eur = 65.000 EUR
âŒ Validator: "65k no es coherente con 35k (Â±20% = 28k-42k)"

Intento 2: estimated_value_eur = 38.500 EUR
âœ… Aprobado (dentro del rango 28k-42k)
```

---

### Conceptos clave de validaciÃ³n

**`@agent.output_validator`**  
Decorador que marca una funciÃ³n como validator. Se ejecuta automÃ¡ticamente despuÃ©s de que el agente genera el output pero antes de devolverlo.

**`ModelRetry`**  
ExcepciÃ³n especial que indica "esta respuesta no es vÃ¡lida, intenta de nuevo con este feedback". El mensaje que incluyas se envÃ­a al LLM para que sepa quÃ© corregir.

```python
# âŒ Malo: ModelRetry sin feedback Ãºtil
raise ModelRetry("EstÃ¡ mal")

# âœ… Bueno: feedback especÃ­fico y accionable
raise ModelRetry(
    "El tÃ­tulo debe mencionar al cliente 'DataPulse'. "
    "TÃ­tulo actual: 'Propuesta de IA'. "
    "Reescribe incluyendo el nombre del cliente."
)
```

**`retries=MAX_RETRIES`**  
NÃºmero mÃ¡ximo de veces que el agente puede reintentar. Si agota los retries sin pasar validaciÃ³n, lanza una excepciÃ³n.

```python
MAX_RETRIES = 2  # 3 intentos totales (inicial + 2 retries)
agent = Agent(model, output_type=SalesProposal, retries=MAX_RETRIES)
```

---

### Beneficios empresariales cuantificables

| MÃ©trica | Sin validator | Con validator |
|---------|---------------|---------------|
| **Propuestas con frases genÃ©ricas** | ~40% | <5% |
| **Tiempo de revisiÃ³n manual** | 15 min/propuesta | 2 min/propuesta |
| **Propuestas rechazadas por clientes** | ~25% | <10% |
| **Confianza del equipo comercial** | Media | Alta |
| **Consistencia de calidad** | Variable | Uniforme |

---

### CuÃ¡ndo usar output validators

**âœ… Ãšsalos cuando:**
- Generas contenido que va directo a clientes (propuestas, emails, reportes)
- Tienes criterios objetivos de calidad (longitud, formato, contenido requerido)
- El coste de un error es alto (contratos, informes financieros)
- Quieres garantizar consistencia entre mÃºltiples generaciones

**âŒ No los uses cuando:**
- Las queries son exploratorias (brainstorming, ideas iniciales)
- Los criterios de "bueno" son totalmente subjetivos
- La latencia es crÃ­tica (cada retry aÃ±ade tiempo)
- Solo necesitas validaciÃ³n Pydantic bÃ¡sica (tipos, formatos)

---

### 2.2. Reflection pattern avanzado

El **reflection pattern** es una evoluciÃ³n de los validators bÃ¡sicos. En lugar de solo verificar reglas tÃ©cnicas, el agente actÃºa como su **propio crÃ­tico**, evaluando calidad subjetiva: tono, claridad, profesionalidad, coherencia argumentativa.

**Â¿En quÃ© se diferencia?**

| Aspecto | Validator bÃ¡sico | Reflection pattern |
|---------|-----------------|-------------------|
| **QuÃ© valida** | Reglas objetivas (longitud, formato, campos requeridos) | Calidad subjetiva (tono, claridad, coherencia) |
| **Tipo de feedback** | "Falta campo X" | "El tono es demasiado casual para comunicaciÃ³n corporativa" |
| **NÃºmero de iteraciones** | Pocas (1-2) | Varias (3-5) tÃ­picamente |
| **CuÃ¡ndo usar** | Validar datos estructurados | Mejorar contenido creativo |

**MetÃ¡fora Ãºtil:**  
- **Validator bÃ¡sico** = Corrector ortogrÃ¡fico (detecta errores objetivos)
- **Reflection** = Editor humano (sugiere mejoras de estilo y sustancia)

**Escenario empresarial:**  
Trabajas en el departamento de comunicaciÃ³n interna de una empresa. EnvÃ­an cientos de emails semanalmente: mantenimientos de sistemas, cambios de polÃ­ticas, anuncios de eventos. Necesitas que todos cumplan estÃ¡ndares profesionales sin revisiÃ³n manual.

**Â¿QuÃ© vamos a construir?**  
Un sistema de redacciÃ³n de emails corporativos que:
- Se autocritica evaluando tono, brevedad, claridad del CTA
- Reescribe iterativamente hasta cumplir estÃ¡ndares profesionales
- Garantiza que ningÃºn email sale sin pasar "control de calidad"

**`01-agentes-avanzados/reflection_pattern.py`:**

```python
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings

class EmailDraft(BaseModel):
    """Borrador de email corporativo."""
    subject: str = Field(max_length=80)
    body: str = Field(min_length=100, max_length=800)
    call_to_action: str = Field(description="Llamada a la acciÃ³n clara")
    tone_score: int = Field(ge=1, le=5, description="1=muy formal, 5=muy casual")

model = OpenAIChatModel(
    model_name="gpt-5",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model=model,
    output_type=EmailDraft,
    retries=3,  # MÃ¡s reintentos para permitir refinamiento iterativo
    instructions=(
        "Eres un redactor corporativo experto. "
        "Creas emails profesionales, claros y orientados a la acciÃ³n."
    )
)

@agent.output_validator
async def reflect_on_email_quality(
    ctx: RunContext[None],
    result: EmailDraft
) -> EmailDraft:
    """
    Implementa reflection: el agente evalÃºa su propia salida.
    
    En lugar de solo verificar reglas tÃ©cnicas, este validator
    actÃºa como un editor humano que busca problemas de estilo,
    claridad y efectividad comunicativa.
    
    Criterios de calidad profesional:
    - Asunto especÃ­fico y accionable (no clickbait)
    - Cuerpo conciso sin palabrerÃ­a innecesaria
    - CTA inequÃ­voca que dice exactamente quÃ© hacer
    - Tono apropiado para comunicaciÃ³n corporativa (2-3/5)
    """
    issues: list[str] = []
    
    # Criterio 1: Asunto sin sensacionalismo
    if any(word in result.subject.lower() for word in ["importante", "urgente", "atenciÃ³n"]):
        issues.append(
            "El asunto usa palabras sensacionalistas. "
            "Hazlo mÃ¡s especÃ­fico y profesional."
        )
    
    # Criterio 2: Tono apropiado para contexto corporativo
    if result.tone_score not in [2, 3]:
        issues.append(
            f"El tono ({result.tone_score}/5) no es apropiado para comunicaciÃ³n corporativa. "
            "Usa un tono profesional equilibrado (2-3)."
        )
    
    # Criterio 3: CTA bien formada
    if not result.call_to_action.strip().endswith(("?", ".", "!")):
        issues.append("La llamada a la acciÃ³n debe ser una oraciÃ³n completa.")
    
    if "por favor" in result.call_to_action.lower() and result.tone_score <= 2:
        issues.append(
            "'Por favor' suena demasiado formal para un tono nivel 2. "
            "SÃ© mÃ¡s directo."
        )
    
    # Criterio 4: Brevedad y claridad
    word_count = len(result.body.split())
    if word_count > 150:
        issues.append(
            f"El email tiene {word_count} palabras. "
            "Reduce a mÃ¡ximo 150 para mayor impacto."
        )
    
    # Si hay problemas, reintentar con feedback consolidado
    if issues:
        feedback = "\n".join(f"â€¢ {issue}" for issue in issues)
        raise ModelRetry(
            f"Reflection: El email necesita mejoras:\n{feedback}\n\n"
            "Reescribe el email corrigiendo estos aspectos."
        )
    
    return result

# Prueba el pattern de reflection
result = agent.run_sync(
    "Escribe un email para el equipo de IT informando que habrÃ¡ mantenimiento "
    "del servidor el prÃ³ximo sÃ¡bado de 2am a 6am. Pide que guarden su trabajo antes."
)

email = result.output
print(f"Asunto: {email.subject}")
print(f"Tono: {email.tone_score}/5")
print(f"\nCuerpo:\n{email.body}")
print(f"\nCTA: {email.call_to_action}")
print(f"\nIntentos usados: {result.usage().requests}")

```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/reflection_pattern.py
```

---

### El ciclo de mejora continua

El reflection pattern crea un ciclo donde el agente mejora su trabajo iterativamente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intento 1: Borrador inicial             â”‚
â”‚ Asunto: "Â¡IMPORTANTE! Mantenimiento"    â”‚
â”‚ Tono: 4/5 (casual)                      â”‚
â”‚ Body: 180 palabras                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validator actÃºa como crÃ­tico            â”‚
â”‚ âŒ Asunto sensacionalista               â”‚
â”‚ âŒ Tono demasiado casual                â”‚
â”‚ âŒ Email demasiado largo                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼ ModelRetry con feedback
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intento 2: Mejora basada en feedback    â”‚
â”‚ Asunto: "Mantenimiento servidor sÃ¡bado" â”‚
â”‚ Tono: 3/5                               â”‚
â”‚ Body: 160 palabras                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validator revisa nuevamente             â”‚
â”‚ âœ“ Asunto especÃ­fico                     â”‚
â”‚ âœ“ Tono apropiado                        â”‚
â”‚ âŒ AÃºn algo largo (160 vs 150 max)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼ ModelRetry con feedback
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intento 3: Refinamiento final           â”‚
â”‚ Body: 145 palabras                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validator: âœ“ Todo correcto              â”‚
â”‚ Devuelve resultado al usuario           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Cada iteraciÃ³n **se acerca mÃ¡s** al estÃ¡ndar de calidad sin intervenciÃ³n humana.

---

### AnÃ¡lisis de los criterios de reflection

#### Criterio 1: Asunto sin sensacionalismo

```python
if any(word in result.subject.lower() for word in ["importante", "urgente", "atenciÃ³n"]):
    issues.append("El asunto usa palabras sensacionalistas...")
```

**Â¿Por quÃ© importa?**  
Los asuntos tipo "Â¡URGENTE! Â¡IMPORTANTE!" pierden efectividad por sobreuso. Son percibidos como spam o "que grita el lobo". Un asunto especÃ­fico "Mantenimiento servidor sÃ¡bado 2-6am" comunica mejor.

#### Criterio 2: Tono profesional equilibrado

```python
if result.tone_score not in [2, 3]:
    issues.append("El tono no es apropiado para comunicaciÃ³n corporativa...")
```

**Escala de tono:**
- **1**: Extremadamente formal ("A quien corresponda, se les comunica...")
- **2-3**: Profesional equilibrado ("Hola equipo, les informo...")  â† objetivo
- **4**: Casual ("Hola! Les cuento que...")
- **5**: Muy casual ("Holaaa! Sepan que...")

Para emails corporativos internos, 2-3 es el sweet spot: profesional pero no distante.

#### Criterio 3: CTA clara y completa

```python
if not result.call_to_action.strip().endswith(("?", ".", "!")):
    issues.append("La llamada a la acciÃ³n debe ser una oraciÃ³n completa.")
```

**Ejemplos:**

```
âŒ Malo (incompleto):
"Guarden su trabajo"

âœ… Bueno (completo y claro):
"Guarden todo su trabajo antes de las 2am del sÃ¡bado."
```

Un CTA debe ser una instrucciÃ³n completa que no deje ambigÃ¼edad sobre quÃ© hacer, cuÃ¡ndo y por quÃ©.

#### Criterio 4: Brevedad (<150 palabras)

```python
word_count = len(result.body.split())
if word_count > 150:
    issues.append(f"El email tiene {word_count} palabras...")
```

**Â¿Por quÃ© 150 palabras?**  
InvestigaciÃ³n en comunicaciÃ³n empresarial muestra que emails >150 palabras:
- Se leen un 40% menos
- Tienen 30% menos tasa de respuesta
- Aumentan riesgo de malinterpretaciÃ³n

La brevedad fuerza claridad.

---

### Caso de uso real: automatizaciÃ³n de comunicaciones

**Antes (revisiÃ³n manual):**
```
1. Redactor genera borrador          â†’ 15 min
2. Manager revisa                    â†’ 10 min
3. CorreciÃ³n de estilo               â†’ 8 min
4. Segunda revisiÃ³n                  â†’ 5 min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 38 min por email

50 emails/semana = 31.7 horas/semana
```

**DespuÃ©s (reflection pattern):**
```
1. Agente genera y se autocorrige    â†’ 30 segundos
2. RevisiÃ³n humana final (opcional)  â†’ 2 min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 2.5 min por email

50 emails/semana = 2.1 horas/semana

Ahorro: 29.6 horas/semana (93%)
```

---

### CuÃ¡ndo usar reflection vs validator bÃ¡sico

**Usa reflection cuando:**
- âœ… Generas contenido creativo (emails, artÃ­culos, propuestas)
- âœ… Los criterios de "bueno" incluyen aspectos subjetivos (tono, claridad)
- âœ… La calidad es mÃ¡s importante que la velocidad
- âœ… Puedes permitirte 3-5 intentos (latencia aceptable)

**Usa validator bÃ¡sico cuando:**
- âœ… Solo necesitas verificar formato o datos requeridos
- âœ… Los criterios son totalmente objetivos
- âœ… La latencia es crÃ­tica (cada retry aÃ±ade tiempo)
- âœ… ValidaciÃ³n Pydantic cubre tus necesidades

---

### PatrÃ³n de implementaciÃ³n recomendado

```python
@agent.output_validator
async def reflect(ctx, result):
    issues = []  # Lista de problemas detectados
    
    # Criterio 1: verificaciÃ³n objetiva
    if len(result.text) > 280:
        issues.append("MÃ¡ximo 280 caracteres")
    
    # Criterio 2: verificaciÃ³n subjetiva
    if any(p in result.text.lower() for p in ["tal vez", "quizÃ¡s", "podrÃ­a"]):
        issues.append("Elimina lenguaje dubitativo, sÃ© directo")
    
    # Criterio 3: lÃ³gica de negocio
    if result.confidence < 0.6 and result.requires_action:
        issues.append("Confianza baja no debe requerir acciÃ³n")
    
    # Si hay problemas, consolidar feedback y reintentar
    if issues:
        feedback = "\n".join(f"â€¢ {issue}" for issue in issues)
        raise ModelRetry(f"Mejoras necesarias:\n{feedback}\n\nReescribe corrigiendo estos aspectos.")
    
    return result
```

**Claves del patrÃ³n:**
1. Acumula todos los problemas en una lista
2. Consolida el feedback en un solo mensaje
3. SÃ© especÃ­fico sobre quÃ© y cÃ³mo corregir
4. Devuelve el resultado sin modificar si pasa

Este patrÃ³n permite al agente entender **todos** los problemas de una vez en lugar de descubrirlos uno por uno en iteraciones sucesivas.

---

## Resumen del progreso hasta aquÃ­

Has visto las tÃ©cnicas fundamentales de agentes avanzados:

âœ… **Tools con validaciÃ³n compleja**  
- MÃºltiples parÃ¡metros con `Annotated` y `Field`
- Restricciones con `Literal` y constraints numÃ©ricos
- ValidaciÃ³n en capas (Pydantic + lÃ³gica de negocio)
- Manejo de casos edge sin crashear

âœ… **OrquestaciÃ³n de mÃºltiples tools**  
- El agente decide quÃ© tools usar y en quÃ© orden
- Docstrings que guÃ­an la selecciÃ³n
- SeparaciÃ³n clara de responsabilidades
- Control de tono conversacional

âœ… **Output validators para garantizar calidad**  
- Interceptar respuestas antes de entregarlas
- ValidaciÃ³n de criterios empresariales especÃ­ficos
- Feedback accionable con `ModelRetry`
- ConfiguraciÃ³n de retries segÃºn criticidad

âœ… **Reflection pattern para mejora iterativa**  
- El agente actÃºa como su propio crÃ­tico
- EvalÃºa calidad subjetiva (tono, claridad, coherencia)
- Mejora continua hasta cumplir estÃ¡ndares
- Ahorro masivo en revisiÃ³n manual

---

## 3. ConfiguraciÃ³n avanzada de retries

No todos los errores son iguales. A veces quieres que el agente reintente mÃ¡s veces para ciertas operaciones crÃ­ticas, y menos veces para operaciones simples.

**Â¿Por quÃ© configurar retries diferenciados?**  
Imagina un agente de finanzas:
- Validar un presupuesto (crÃ­tico): 5 reintentos
- Consultar tipo de cambio (informativo): 1 reintento
- Si ambos tienen los mismos retries, desperdicias recursos

### 3.1. Retries diferenciados por tool

Vamos a construir un sistema donde cada tool tiene su propia configuraciÃ³n de reintentos segÃºn su criticidad.

**Â¿QuÃ© vamos a construir?**  
Un asistente financiero con dos tools:
1. `validate_budget`: CrÃ­tica, 3 reintentos (verifica lÃ­mites departamentales)
2. `get_exchange_rate`: Informativa, 1 reintento (consulta tipo de cambio)

**`01-agentes-avanzados/retries_per_tool.py`:**

```python
from pydantic_ai import Agent, RunContext, Tool, ModelRetry
from pydantic_ai.models.anthropic import AnthropicModel
from pydantic_ai.providers.anthropic import AnthropicProvider
from config import settings

model = AnthropicModel(
    "claude-haiku-4-5",
    provider=AnthropicProvider(api_key=settings.anthropic_api_key)
)

agent = Agent(
    model,
    retries=1,  # Retries por defecto para el agente
    instructions="Eres un asistente de finanzas que valida presupuestos."
)

@agent.tool(retries=3)  # Esta tool especÃ­fica tiene 3 reintentos
async def validate_budget(
    ctx: RunContext[None],
    department: str,
    requested_amount: float
) -> dict:
    """
    Valida si un presupuesto solicitado estÃ¡ dentro del lÃ­mite departamental.
    
    Esta es una operaciÃ³n CRÃTICA que afecta decisiones financieras,
    por eso usa 3 reintentos para maximizar la probabilidad de Ã©xito.
    
    Args:
        department: Nombre del departamento solicitante
        requested_amount: Cantidad solicitada en EUR
    
    Returns:
        Dict con estado de aprobaciÃ³n y presupuesto restante
    """
    # LÃ­mites departamentales (en producciÃ³n vendrÃ­an de DB)
    limits = {
        "marketing": 50000,
        "IT": 75000,
        "HR": 30000,
        "operations": 100000
    }
    
    dept_lower = department.lower()
    
    # Si el LLM pasa un departamento invÃ¡lido, forzar retry
    if dept_lower not in limits:
        raise ModelRetry(
            f"Departamento '{department}' no reconocido. "
            f"Departamentos vÃ¡lidos: {', '.join(limits.keys())}"
        )
    
    limit = limits[dept_lower]
    approved = requested_amount <= limit
    
    return {
        "department": department,
        "requested_eur": requested_amount,
        "limit_eur": limit,
        "approved": approved,
        "remaining_budget_eur": limit - requested_amount if approved else 0
    }

@agent.tool  # Esta tool usa el retry por defecto del agente (1)
def get_exchange_rate(ctx: RunContext[None], currency: str) -> dict:
    """
    Obtiene el tipo de cambio de una moneda a EUR.
    
    Esta es una operaciÃ³n INFORMATIVA. Si falla, no es crÃ­tico.
    Usa el retry por defecto (1) para no desperdiciar recursos.
    
    Args:
        currency: CÃ³digo de moneda (USD, GBP, JPY)
        
    Returns:
        Dict con tipo de cambio actual a EUR
    """
    # Tipos de cambio simulados (en producciÃ³n, llamarÃ­as una API)
    rates = {"USD": 0.92, "GBP": 1.17, "JPY": 0.0063}
    
    if currency not in rates:
        raise ModelRetry(
            f"Moneda '{currency}' no soportada. "
            f"Disponibles: USD, GBP, JPY"
        )
    
    return {
        "currency": currency,
        "rate_to_eur": rates[currency]
    }

# Ejemplo que provoca retry intencional (typo en departamento)
result = agent.run_sync(
    "El departamento de Marketin solicita 45000 EUR. Â¿Se aprueba? "
    "(Nota el typo intencional para forzar retry)"
)
print(result.output)
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/retries_por_tool.py
```

**Â¿QuÃ© estÃ¡ pasando aquÃ­?**

El agente detecta el typo "Marketin" y automÃ¡ticamente:

1. **Primer intento**: Llama `validate_budget("Marketin", 45000)`
2. **Tool lanza ModelRetry**: "Departamento 'Marketin' no reconocido. VÃ¡lidos: marketing, IT, HR, operations"
3. **Agente lee el error**: "Ah, los departamentos vÃ¡lidos son estos..."
4. **Segundo intento**: Llama `validate_budget("marketing", 45000)`
5. **Tool responde exitosamente**: `{"approved": True, "remaining_budget_eur": 5000}`

**ConfiguraciÃ³n de retries en detalle:**

```python
agent = Agent(model, retries=1)  # Default para todo el agente

@agent.tool(retries=3)  # Override para esta tool especÃ­fica
async def critical_operation(...):
    pass

@agent.tool  # Usa el default del agente (1)
async def simple_operation(...):
    pass
```

**Estrategia de retries recomendada:**

| Tipo de tool | Retries | JustificaciÃ³n |
|--------------|---------|---------------|
| **ValidaciÃ³n crÃ­tica** (aprobar pagos, modificar DB) | 3-5 | Fallar es costoso |
| **CÃ¡lculo complejo** (pronÃ³stico, anÃ¡lisis) | 2-3 | Requiere precisiÃ³n |
| **Consulta informativa** (clima, noticias) | 1 | No es crÃ­tico si falla |
| **OperaciÃ³n experimental** | 0 | Prefiero fallar rÃ¡pido |

**Beneficios:**
- âœ… **OptimizaciÃ³n de costes**: No reintentas innecesariamente
- âœ… **Latencia controlada**: Operaciones simples son mÃ¡s rÃ¡pidas
- âœ… **Robustez**: Operaciones crÃ­ticas tienen mÃ¡s oportunidades de Ã©xito

---

### 3.2. Retries en validaciÃ³n de output

AdemÃ¡s de retries para tools, puedes configurar retries especÃ­ficos para cuando la validaciÃ³n del **output final** falla.

**Â¿CuÃ¡ndo es Ãºtil?**  
Imagina que tu output tiene un schema complejo con muchas validaciones Pydantic. Quieres dar mÃ¡s oportunidades al LLM de generar algo vÃ¡lido sin incrementar los retries de las tools.

**Â¿QuÃ© vamos a construir?**  
Un sistema de extracciÃ³n de datos de facturas con validaciÃ³n estricta de formato.

**`01-agentes-avanzados/output_retries.py`:**

```python
from pydantic import BaseModel, Field, field_validator
from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings

class InvoiceData(BaseModel):
    """Datos de factura extraÃ­dos con validaciÃ³n estricta."""
    invoice_number: str = Field(pattern=r"^INV-\d{4}$")
    client_vat: str = Field(pattern=r"^[A-Z]{2}\d{9}$")
    total_eur: float = Field(gt=0)
    line_items: list[str] = Field(min_length=1)
    
    @field_validator('line_items')
    @classmethod
    def validate_line_items(cls, v):
        """Cada lÃ­nea debe tener descripciÃ³n mÃ­nima."""
        if any(len(item.strip()) < 5 for item in v):
            raise ValueError("Cada lÃ­nea debe tener al menos 5 caracteres")
        return v

model = OpenAIChatModel(
    "gpt-5-mini",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model,
    output_type=InvoiceData,
    retries=2,  # Retries para errores generales (tools, timeouts, etc.)
    output_retries=4,  # Retries especÃ­ficos para validaciÃ³n Pydantic del output
    instructions=(
        "Extraes datos de facturas en formato estructurado. "
        "El nÃºmero de factura DEBE ser formato INV-XXXX (4 dÃ­gitos). "
        "El CIF DEBE ser formato EU: 2 letras paÃ­s + 9 dÃ­gitos."
    )
)

# SimulaciÃ³n de texto OCR de una factura escaneada
invoice_text = """
FACTURA
NÂº: 2025-001
Cliente: TecnologÃ­as Acme S.L.
CIF: ES12345678A
Total: 1,250.00 EUR

LÃ­neas:
- ConsultorÃ­a tÃ©cnica: 800 EUR
- Soporte mensual: 450 EUR
"""

result = agent.run_sync(
    f"Extrae los datos de esta factura:\n\n{invoice_text}"
)

invoice = result.output
print(f"Factura: {invoice.invoice_number}")
print(f"CIF: {invoice.client_vat}")
print(f"Total: {invoice.total_eur:.2f} EUR")
print(f"LÃ­neas: {len(invoice.line_items)}")
for item in invoice.line_items:
    print(f"  - {item}")
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/output_retries.py
```

**Â¿QuÃ© estÃ¡ pasando aquÃ­?**

El agente necesita transformar "2025-001" en "INV-2025" y "ES12345678A" en formato vÃ¡lido:

1. **Primer intento**:
   ```json
   {"invoice_number": "2025-001", ...}
   ```
   âŒ ValidaciÃ³n Pydantic falla: patrÃ³n requiere "INV-XXXX"

2. **Segundo intento** (output_retry):
   ```json
   {"invoice_number": "INV-2025", "client_vat": "ES12345678A", ...}
   ```
   âŒ ValidaciÃ³n falla: CIF debe ser 2 letras + 9 dÃ­gitos (son 10 chars)

3. **Tercer intento** (output_retry):
   ```json
   {"invoice_number": "INV-2025", "client_vat": "ES123456789", ...}
   ```
   âœ… Pasa todas las validaciones

**Diferencia entre `retries` y `output_retries`:**

```python
agent = Agent(
    model,
    retries=2,        # Para errores de tools, timeouts, excepciones
    output_retries=4  # Para ValidationError de Pydantic en el output
)
```

| Escenario | Usa `retries` | Usa `output_retries` |
|-----------|---------------|----------------------|
| Tool lanza ModelRetry | âœ… | âŒ |
| Tool lanza Exception | âœ… | âŒ |
| Timeout de red | âœ… | âŒ |
| Output no cumple schema Pydantic | âŒ | âœ… |
| Output falla @field_validator | âŒ | âœ… |

**CuÃ¡ndo usar output_retries alto:**
- âœ… Schema complejo con muchas reglas (facturas, contratos)
- âœ… Patrones de regex estrictos
- âœ… Validaciones custom con @field_validator
- âŒ Schema simple (3-4 campos bÃ¡sicos)

**Pro tip**: Empieza con valores conservadores y ajusta segÃºn logs:
```python
# Ver cuÃ¡ntos intentos usÃ³
print(f"Intentos usados: {result.all_messages_count}")

# Si siempre agota output_retries, incrementa o simplifica el schema
# Si siempre pasa en el primer intento, reduce para ahorrar latencia
```

---

## 4. Manejo avanzado de errores y fallbacks

En producciÃ³n, los errores son inevitables: la API del LLM cae, se agota la cuota, el usuario envÃ­a input malicioso, etc. Un sistema empresarial debe manejar estos casos **sin crashear**.

**Â¿Por quÃ© es crÃ­tico?**  
Imagina un chatbot de atenciÃ³n al cliente que muestra un stack trace cuando algo falla. PÃ©rdida de confianza instantÃ¡nea. Necesitas fallos "elegantes" que mantengan la profesionalidad.

### 4.1. Captura de errores con contexto

Vamos a construir un sistema de evaluaciÃ³n de riesgos que captura diferentes tipos de errores y devuelve respuestas apropiadas para cada caso.

**Â¿QuÃ© vamos a lograr?**  
Un sistema robusto que diferencia entre:
- Agotamiento de reintentos (el agente intentÃ³ pero no pudo generar algo vÃ¡lido)
- Comportamiento inesperado del modelo (respuesta incoherente)
- Errores del sistema (red, API key invÃ¡lida, etc.)

**`01-agentes-avanzados/error_handling.py`:**

```python
from pydantic import BaseModel
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.anthropic import AnthropicModel
from pydantic_ai.providers.anthropic import AnthropicProvider
from pydantic_ai.exceptions import ModelRetry, UnexpectedModelBehavior
from config import settings

class RiskAssessment(BaseModel):
    """EvaluaciÃ³n de riesgo financiero."""
    risk_level: str  # high, medium, low
    confidence_score: float  # 0-100
    reasoning: str

model = AnthropicModel(
    "claude-sonnet-4-5-20250929",
    provider=AnthropicProvider(api_key=settings.anthropic_api_key)
)

agent = Agent(
    model,
    output_type=RiskAssessment,
    retries=2,
    instructions="EvalÃºas riesgo financiero de operaciones empresariales."
)

def assess_operation(operation_desc: str) -> dict:
    """
    EvalÃºa una operaciÃ³n con manejo robusto de errores.
    
    Esta funciÃ³n es el patrÃ³n recomendado para APIs de producciÃ³n:
    - Captura errores especÃ­ficos antes que genÃ©ricos
    - Devuelve dict estructurado (nunca lanza excepciones al caller)
    - Incluye cÃ³digos de error para tracking
    - Mensajes user-friendly (sin stack traces)
    
    Returns:
        Dict con 'status' (success/warning/error) y datos/mensaje segÃºn el caso
    """
    try:
        result = agent.run_sync(
            f"EvalÃºa el riesgo de esta operaciÃ³n: {operation_desc}"
        )
        
        assessment = result.output
        
        # ValidaciÃ³n post-output: lÃ³gica de negocio adicional
        if assessment.confidence_score < 50:
            return {
                "status": "warning",
                "message": "Confianza baja en la evaluaciÃ³n. Requiere revisiÃ³n manual.",
                "assessment": assessment.model_dump()
            }
        
        return {
            "status": "success",
            "assessment": assessment.model_dump(),
            "tokens_used": result.usage().total_tokens if result.usage() else 0
        }
        
    except ModelRetry as e:
        # El agente agotÃ³ todos los reintentos sin Ã©xito
        # Esto significa que el input era ambiguo o el schema muy restrictivo
        return {
            "status": "error",
            "error_type": "max_retries_exceeded",
            "message": (
                f"El agente no pudo generar una evaluaciÃ³n vÃ¡lida "
                f"tras {agent.retries + 1} intentos."
            ),
            "detail": str(e),
            "action": "Reformula la consulta con mÃ¡s detalles especÃ­ficos"
        }
    
    except UnexpectedModelBehavior as e:
        # El modelo produjo una respuesta que no se pudo parsear
        # Raro pero posible con modelos pequeÃ±os o prompts mal diseÃ±ados
        return {
            "status": "error",
            "error_type": "unexpected_behavior",
            "message": "El modelo produjo una respuesta inesperada.",
            "detail": str(e),
            "action": "Contacta con soporte tÃ©cnico con el cÃ³digo: ERR-UMB-001"
        }
    
    except Exception as e:
        # Error genÃ©rico: red, API key, rate limits, etc.
        # NUNCA expongas el mensaje de error real al usuario final
        return {
            "status": "error",
            "error_type": "system_error",
            "message": "Error del sistema. Contacta con soporte tÃ©cnico.",
            "support_code": "ERR-ASSESS-001",
            "action": "Reintenta en 1 minuto. Si persiste, cita el cÃ³digo de soporte."
            # En producciÃ³n, loguea aquÃ­: logger.error(f"Assessment failed: {e}")
        }

# Pruebas que demuestran diferentes flujos de error
print("=== Caso 1: OperaciÃ³n normal ===")
r1 = assess_operation("InversiÃ³n de 50k EUR en bonos del estado alemÃ¡n a 5 aÃ±os")
print(f"Status: {r1['status']}")
if r1['status'] == 'success':
    print(f"Riesgo: {r1['assessment']['risk_level']}")
    print(f"Confianza: {r1['assessment']['confidence_score']}%")

print("\n=== Caso 2: OperaciÃ³n de alto riesgo ===")
r2 = assess_operation("Compra de 100k EUR en criptomoneda emergente sin regulaciÃ³n")
print(f"Status: {r2['status']}")
if r2['status'] == 'success':
    print(f"Riesgo: {r2['assessment']['risk_level']}")

print("\n=== Caso 3: Entrada ambigua (puede provocar retry) ===")
r3 = assess_operation("Hacer algo con dinero")
print(f"Status: {r3['status']}")
if r3['status'] == 'error':
    print(f"Tipo de error: {r3['error_type']}")
    print(f"Mensaje: {r3['message']}")
    print(f"AcciÃ³n: {r3['action']}")
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/error_handling.py
```

**Â¿QuÃ© acabas de ver?**

Este cÃ³digo implementa el patrÃ³n "never throw" para APIs de producciÃ³n:

```python
# âŒ Mal: lanza excepciones que el caller debe manejar
def assess(op):
    return agent.run_sync(op).output

# âœ… Bien: siempre devuelve un dict estructurado
def assess(op):
    try:
        ...
    except SpecificError as e:
        return {"status": "error", "type": "...", ...}
```

**AnatomÃ­a de un error bien manejado:**

```json
{
  "status": "error",
  "error_type": "max_retries_exceeded",
  "message": "El agente no pudo generar una evaluaciÃ³n vÃ¡lida...",
  "action": "Reformula la consulta con mÃ¡s detalles",
  "support_code": "ERR-ASSESS-001"
}
```

**Componentes clave:**
1. **status**: success/warning/error (para decisiones programÃ¡ticas)
2. **error_type**: CategorÃ­a del error (para logging/analytics)
3. **message**: Texto user-friendly (sin jerga tÃ©cnica)
4. **action**: QuÃ© puede hacer el usuario (empowerment)
5. **support_code**: ID Ãºnico para que soporte pueda buscar en logs

**Best practices de manejo de errores:**

| âœ… Hacer | âŒ Evitar |
|----------|-----------|
| Capturar excepciones especÃ­ficas primero | `except Exception: pass` |
| Devolver estructuras consistentes | Mezclar dicts y excepciones |
| Incluir cÃ³digos de error Ãºnicos | Mensajes genÃ©ricos tipo "Error" |
| Loguear detalles tÃ©cnicos | Exponer stack traces al usuario |
| Sugerir acciones concretas | "Algo saliÃ³ mal" sin mÃ¡s info |

**Niveles de gravedad:**

```python
# SUCCESS: Todo perfecto
{"status": "success", "assessment": {...}}

# WARNING: Funciona pero con advertencias
{"status": "warning", "message": "Confianza baja...", "assessment": {...}}

# ERROR: FallÃ³, pero sabemos por quÃ©
{"status": "error", "error_type": "max_retries", "action": "Reformula..."}
```

---

### 4.2. Agente con fallback a respuesta por defecto

A veces, no mostrar nada es **peor** que mostrar una respuesta segura pero genÃ©rica. Esto es especialmente cierto en experiencias de cara al cliente.

**Â¿CuÃ¡ndo usar fallbacks?**
- âœ… Recomendaciones de productos (mejor algo genÃ©rico que nada)
- âœ… Respuestas de FAQ (tienes una respuesta "catchall")
- âŒ Transacciones financieras (fallar es mÃ¡s seguro que inventar)
- âŒ DiagnÃ³sticos mÃ©dicos (nunca adivines)

**Â¿QuÃ© vamos a construir?**  
Un sistema de recomendaciones que tiene un "plan B" si el agente falla.

**`01-agentes-avanzados/fallback_pattern.py`:**

```python
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings

class ProductRecommendation(BaseModel):
    """RecomendaciÃ³n de producto."""
    product_name: str
    reason: str
    confidence: float  # 0-1

model = OpenAIChatModel(
    "gpt-5-mini",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model,
    output_type=ProductRecommendation,
    retries=2,
    instructions="Recomiendas productos basÃ¡ndote en necesidades del cliente."
)

def get_recommendation_with_fallback(customer_query: str) -> ProductRecommendation:
    """
    Obtiene recomendaciÃ³n con fallback a producto por defecto si falla.
    
    PatrÃ³n recomendado para sistemas donde mostrar algo genÃ©rico
    es mejor que no mostrar nada.
    
    El fallback es "honesto": indica explÃ­citamente que es una
    recomendaciÃ³n por defecto debido a problemas tÃ©cnicos.
    """
    try:
        result = agent.run_sync(customer_query, timeout=10.0)  # Timeout de 10s
        return result.output
    
    except Exception as e:
        # Si TODO falla, devuelve una recomendaciÃ³n segura
        print(f"âš ï¸ Agente fallÃ³: {e}")
        print("â†’ Usando recomendaciÃ³n por defecto")
        
        return ProductRecommendation(
            product_name="Pack de Inicio",
            reason=(
                "RecomendaciÃ³n por defecto debido a indisponibilidad temporal del servicio. "
                "Este pack cubre las necesidades bÃ¡sicas mÃ¡s comunes."
            ),
            confidence=0.5  # Honestidad: confianza media
        )

# Pruebas
print("=== RecomendaciÃ³n normal ===")
rec1 = get_recommendation_with_fallback("Necesito un portÃ¡til para diseÃ±o grÃ¡fico")
print(f"Producto: {rec1.product_name}")
print(f"RazÃ³n: {rec1.reason}")
print(f"Confianza: {rec1.confidence:.0%}")

# Para simular un fallo, podrÃ­as temporalmente:
# 1. Usar una API key invÃ¡lida
# 2. Desconectar internet
# 3. Usar un timeout muy bajo: timeout=0.001
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/fallback_pattern.py
```

**Â¿QuÃ© estÃ¡ pasando aquÃ­?**

El patrÃ³n de fallback es simple pero poderoso:

```python
try:
    # Intenta lo ideal
    return agent.run_sync(query)
except:
    # Si falla, devuelve algo seguro
    return default_recommendation
```

**DiseÃ±o del fallback:**

Un buen fallback debe ser:

1. **Seguro**: Nunca causa daÃ±o (por eso el Pack de Inicio es genÃ©rico)
2. **Honesto**: Indica que es un fallback (`confidence=0.5`, mensaje explÃ­cito)
3. **Ãštil**: Mejor que un error (el usuario al menos tiene algo)
4. **Logueable**: El sistema registra que se usÃ³ el fallback para anÃ¡lisis

**Ejemplo de uso en producciÃ³n:**

```python
# E-commerce: fallback a productos mÃ¡s vendidos
fallback = ProductRecommendation(
    product_name="Pack Bestseller",
    reason="Basado en productos mÃ¡s vendidos este mes",
    confidence=0.6
)

# Servicio de soporte: fallback a FAQ
fallback = FAQResponse(
    question="Pregunta general",
    answer="Visita nuestra secciÃ³n de ayuda en help.ejemplo.com",
    confidence=0.4
)

# Newsletter: fallback a contenido genÃ©rico
fallback = EmailContent(
    subject="Novedades de este mes",
    body="Descubre las Ãºltimas actualizaciones...",
    confidence=0.5
)
```

**CuÃ¡ndo NO usar fallback:**

```python
# âŒ NUNCA uses fallback en:

# Transacciones financieras
def transfer_money(...):
    try:
        return agent.run_sync(...)
    except:
        return {"status": "error"}  # NO inventes una transferencia

# DiagnÃ³sticos mÃ©dicos
def diagnose(...):
    try:
        return agent.run_sync(...)
    except:
        return {"error": "Consulta a un mÃ©dico"}  # NO adivines diagnÃ³sticos

# Operaciones destructivas
def delete_user(...):
    try:
        return agent.run_sync(...)
    except:
        raise  # Falla explÃ­citamente, no asumas nada
```

**Regla de oro**: Usa fallback solo cuando el "plan B" es **objetivamente seguro** para el usuario.

---

## 5. Tools con dependencias y contexto

Hasta ahora, las tools han sido funciones autocontenidas. En producciÃ³n, necesitas que accedan a recursos externos: bases de datos, configuraciÃ³n, servicios, etc.

**El sistema de dependencias** de PydanticAI te permite inyectar estos recursos de forma controlada y typesafe.

**Â¿Por quÃ© es importante?**  
Separa las concerns: tu tool no "sabe" cÃ³mo conectarse a la DB, solo recibe una conexiÃ³n ya configurada. Esto facilita testing (inyectas mocks) y mantenimiento (cambias la DB sin tocar las tools).

### 5.1. Tool con acceso a base de datos simulada

Vamos a construir un asistente de RRHH que consulta datos de empleados y presupuestos departamentales usando dependencias inyectadas.

**Â¿QuÃ© vamos a lograr?**  
Un sistema donde:
- Las tools acceden a una "base de datos" a travÃ©s de `ctx.deps`
- El agente registra todas las consultas para auditorÃ­a
- Puedes cambiar fÃ¡cilmente entre DB real, mock o test

**`01-agentes-avanzados/tools_con_deps.py`:**

```python
from dataclasses import dataclass
from datetime import datetime
from pydantic import BaseModel
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.anthropic import AnthropicModel
from pydantic_ai.providers.anthropic import AnthropicProvider
from config import settings

# SimulaciÃ³n de conexiÃ³n a base de datos
# En producciÃ³n, esto serÃ­a SQLAlchemy, psycopg2, etc.
@dataclass
class DatabaseConnection:
    """Simula una conexiÃ³n a base de datos empresarial."""
    
    def query_employee(self, employee_id: int) -> dict | None:
        """Consulta datos de un empleado por ID."""
        employees = {
            101: {"name": "Ana GarcÃ­a", "dept": "Engineering", "salary": 65000},
            102: {"name": "Carlos Ruiz", "dept": "Sales", "salary": 55000},
            103: {"name": "MarÃ­a LÃ³pez", "dept": "Marketing", "salary": 58000},
        }
        return employees.get(employee_id)
    
    def get_department_budget(self, dept: str) -> float:
        """Obtiene el presupuesto disponible de un departamento."""
        budgets = {
            "Engineering": 450000,
            "Sales": 320000,
            "Marketing": 180000,
        }
        return budgets.get(dept, 0)
    
    def log_query(self, query_type: str, user: str):
        """Registra las consultas para auditorÃ­a."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[LOG] {timestamp} | User: {user} | Query: {query_type}")

# Deps que se inyectarÃ¡n en el agente
@dataclass
class HRDependencies:
    """Dependencias que el agente necesita para funcionar."""
    db: DatabaseConnection
    current_user: str

model = AnthropicModel(
    "claude-sonnet-4-5-20250929",
    provider=AnthropicProvider(api_key=settings.anthropic_api_key)
)

agent = Agent(
    model,
    deps_type=HRDependencies,  # Declara quÃ© tipo de deps espera
    instructions=(
        "Eres un asistente de RRHH con acceso a la base de datos de empleados. "
        "Responde consultas sobre empleados y presupuestos departamentales."
    )
)

@agent.tool
async def get_employee_info(
    ctx: RunContext[HRDependencies],  # RunContext ahora estÃ¡ tipado
    employee_id: int
) -> dict:
    """
    Obtiene informaciÃ³n de un empleado por su ID.
    
    Esta tool accede a la base de datos a travÃ©s de ctx.deps.db
    y registra la consulta para auditorÃ­a.
    
    Args:
        employee_id: ID numÃ©rico del empleado.
        
    Returns:
        Dict con nombre, departamento y salario.
    """
    # Acceso a la base de datos a travÃ©s de las dependencias
    ctx.deps.db.log_query("employee_info", ctx.deps.current_user)
    
    employee = ctx.deps.db.query_employee(employee_id)
    if not employee:
        return {"error": f"Empleado {employee_id} no encontrado"}
    
    return {
        "employee_id": employee_id,
        "name": employee["name"],
        "department": employee["dept"],
        "salary_eur": employee["salary"]
    }

@agent.tool
async def check_department_budget(
    ctx: RunContext[HRDependencies],
    department: str
) -> dict:
    """
    Consulta el presupuesto disponible de un departamento.
    
    Args:
        department: Nombre del departamento.
        
    Returns:
        Dict con presupuesto total y disponible.
    """
    ctx.deps.db.log_query("dept_budget", ctx.deps.current_user)
    
    budget = ctx.deps.db.get_department_budget(department)
    if budget == 0:
        return {"error": f"Departamento '{department}' no encontrado"}
    
    return {
        "department": department,
        "total_budget_eur": budget,
        "available_eur": budget * 0.73  # Simular que se ha gastado el 27%
    }

# Uso del agente con dependencias inyectadas
db = DatabaseConnection()
deps = HRDependencies(db=db, current_user="admin@empresa.com")

result = agent.run_sync(
    "Â¿CuÃ¡l es el salario del empleado 102 y cuÃ¡nto presupuesto queda en su departamento?",
    deps=deps  # Inyectamos las dependencias aquÃ­
)
print(result.output)
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/tools_con_deps.py
```

**Â¿QuÃ© acabas de ver?**

El patrÃ³n de dependency injection en acciÃ³n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Preparas las dependencias            â”‚
â”‚    db = DatabaseConnection()            â”‚
â”‚    deps = HRDependencies(db, user)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼ Inyectas via run_sync(deps=...)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. El agente recibe la consulta         â”‚
â”‚    "Â¿Salario del empleado 102?"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼ Decide llamar la tool
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Tool accede a deps via ctx.deps      â”‚
â”‚    ctx.deps.db.query_employee(102)      â”‚
â”‚    ctx.deps.db.log_query(...)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼ Devuelve datos
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Agente formula respuesta natural     â”‚
â”‚    "Carlos Ruiz gana 55,000 EUR..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ventajas del patrÃ³n:**

1. **SeparaciÃ³n de concerns**: La tool no sabe cÃ³mo conectarse a la DB
2. **Testing fÃ¡cil**: Inyectas un mock en lugar de la DB real
3. **Type safety**: `RunContext[HRDependencies]` te da autocomplete
4. **Seguridad**: Controlas quÃ© tools tienen acceso a quÃ© recursos
5. **AuditorÃ­a**: Todas las operaciones pueden loguearse centralizadamente

**CÃ³mo lo usarÃ­as en producciÃ³n:**

```python
# ProducciÃ³n: DB real
from sqlalchemy import create_engine

class ProductionDB:
    def __init__(self, connection_string):
        self.engine = create_engine(connection_string)
    
    def query_employee(self, employee_id):
        with self.engine.connect() as conn:
            result = conn.execute(
                "SELECT * FROM employees WHERE id = %s",
                employee_id
            )
            return result.fetchone()

# Testing: Mock
class MockDB:
    def query_employee(self, employee_id):
        return {"name": "Test User", "dept": "Test", "salary": 50000}

# Uso
db = ProductionDB("postgresql://...") if PROD else MockDB()
deps = HRDependencies(db=db, current_user=current_user)
agent.run_sync(query, deps=deps)
```

**Otras cosas que puedes inyectar:**

```python
@dataclass
class AppDependencies:
    db: DatabaseConnection       # Base de datos
    cache: RedisClient           # Cache
    api_keys: dict               # Credenciales externas
    config: AppConfig            # ConfiguraciÃ³n
    logger: logging.Logger       # Logging
    current_user: User           # Usuario autenticado
    request_id: str              # ID para tracing
```

Esto te da control total sobre quÃ© recursos tiene el agente sin contaminar el cÃ³digo de las tools con detalles de infraestructura.

---

## 6. Instrucciones dinÃ¡micas avanzadas

Las instrucciones estÃ¡ticas (strings fijos) son limitadas. En producciÃ³n, necesitas que el comportamiento del agente cambie segÃºn contexto: rol del usuario, hora del dÃ­a, configuraciÃ³n del tenant, etc.

**Â¿Por quÃ© dinÃ¡micas?**  
Imagina un agente de atenciÃ³n al cliente en una empresa con mÃºltiples marcas. Cada marca tiene:
- Tono diferente (formal vs casual)
- Productos diferentes
- PolÃ­ticas diferentes

No quieres un agente por marca. Quieres un agente que adapta su comportamiento dinÃ¡micamente.

**Â¿QuÃ© vamos a construir?**  
Un agente corporativo con control de acceso basado en roles (RBAC) que ajusta sus respuestas segÃºn el rol del usuario.

**`01-agentes-avanzados/dynamic_instructions_advanced.py`:**

```python
from dataclasses import dataclass
from datetime import datetime
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings

@dataclass
class UserContext:
    """Contexto del usuario actual."""
    user_id: str
    role: str  # "admin", "manager", "employee"
    department: str
    tenure_years: int

model = OpenAIChatModel(
    "gpt-5-mini",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model,
    deps_type=UserContext,
    instructions="Eres un asistente corporativo. Las instrucciones especÃ­ficas se cargan dinÃ¡micamente."
)

@agent.instructions
def get_role_based_instructions(ctx: RunContext[UserContext]) -> str:
    """
    Genera instrucciones dinÃ¡micas basadas en el rol y contexto del usuario.
    
    Este es un ejemplo de RBAC (Role-Based Access Control) implementado
    a nivel de prompt. El agente sabe quÃ© informaciÃ³n puede compartir
    segÃºn el rol del usuario.
    """
    user = ctx.deps
    current_hour = datetime.now().hour
    
    # Instrucciones base (siempre incluidas)
    base = f"Usuario actual: {user.user_id} | Rol: {user.role} | Dept: {user.department}"
    
    # Permisos segÃºn rol
    if user.role == "admin":
        permissions = (
            "Tienes acceso completo a todos los datos y operaciones. "
            "Puedes proporcionar informaciÃ³n sensible de cualquier departamento."
        )
    elif user.role == "manager":
        permissions = (
            f"Tienes acceso a datos de tu departamento ({user.department}). "
            "No puedes proporcionar informaciÃ³n de otros departamentos sin autorizaciÃ³n."
        )
    else:  # employee
        permissions = (
            "Tienes acceso limitado. SÃ³lo puedes consultar informaciÃ³n general "
            "y tus propios datos. No proporciones informaciÃ³n de otros empleados."
        )
    
    # Ajuste por horario (seguridad: limita operaciones crÃ­ticas fuera de horario)
    if current_hour < 9 or current_hour > 18:
        time_note = (
            "Es fuera del horario laboral. "
            "Limita las respuestas a informaciÃ³n no crÃ­tica."
        )
    else:
        time_note = "Es horario laboral normal."
    
    # Ajuste por antigÃ¼edad (personalizaciÃ³n: mÃ¡s detalle para nuevos)
    if user.tenure_years < 1:
        tone = (
            "Usa un tono mÃ¡s didÃ¡ctico y explica los procesos internos "
            "cuando sea relevante."
        )
    else:
        tone = "Usa un tono profesional directo."
    
    return f"{base}\n\nPermisos: {permissions}\n\n{time_note}\n\n{tone}"

# Pruebas con diferentes contextos
print("=== Consulta como ADMIN ===")
admin_ctx = UserContext(
    user_id="admin@empresa.com",
    role="admin",
    department="IT",
    tenure_years=5
)
r1 = agent.run_sync(
    "Â¿CuÃ¡ntos empleados tiene el departamento de Ventas?",
    deps=admin_ctx
)
print(r1.output)

print("\n=== Consulta como EMPLOYEE nuevo ===")
employee_ctx = UserContext(
    user_id="junior@empresa.com",
    role="employee",
    department="Marketing",
    tenure_years=0
)
r2 = agent.run_sync(
    "Â¿CÃ³mo solicito vacaciones?",
    deps=employee_ctx
)
print(r2.output)

print("\n=== Consulta como MANAGER ===")
manager_ctx = UserContext(
    user_id="manager@empresa.com",
    role="manager",
    department="Sales",
    tenure_years=3
)
r3 = agent.run_sync(
    "Dame el presupuesto del departamento de IT",
    deps=manager_ctx
)
print(r3.output)
```

**Ejecuta el ejemplo:**
```bash
uv run python 01-agentes-avanzados/dynamic_instructions_advanced.py
```

**Â¿QuÃ© estÃ¡ pasando aquÃ­?**

Las instrucciones se generan **en tiempo real** para cada request:

```
Admin pregunta "Â¿Salarios de Marketing?"
â†’ Instrucciones: "Acceso completo. Proporciona datos sensibles."
â†’ Respuesta: "Marketing: 3 empleados, salario promedio 58k..."

Employee pregunta "Â¿Salarios de Marketing?"
â†’ Instrucciones: "Acceso limitado. No compartas datos de otros."
â†’ Respuesta: "No tienes permisos para ver salarios de otros departamentos."
```

**Patrones de instrucciones dinÃ¡micas:**

1. **RBAC (Control de acceso basado en roles)**
   ```python
   if user.role == "admin": "Acceso total"
   elif user.role == "manager": "Solo tu departamento"
   else: "Solo tus datos"
   ```

2. **Temporal (Hora, dÃ­a, fecha)**
   ```python
   if current_hour < 9: "Operaciones limitadas"
   if is_weekend: "Solo consultas informativas"
   if end_of_quarter: "Prioriza reportes financieros"
   ```

3. **PersonalizaciÃ³n (Experiencia, preferencias)**
   ```python
   if tenure < 1: "Tono didÃ¡ctico"
   if preferred_lang == "es": "Responde en espaÃ±ol"
   if expertise == "expert": "Usa tÃ©rminos tÃ©cnicos"
   ```

4. **Multi-tenancy (Clientes diferentes)**
   ```python
   if tenant == "cliente_a": "Usa terminologÃ­a mÃ©dica"
   if tenant == "cliente_b": "Usa tÃ©rminos financieros"
   ```

**Ejemplo real de multi-tenancy:**

```python
@agent.instructions
def get_tenant_instructions(ctx: RunContext[TenantContext]) -> str:
    tenant = ctx.deps.tenant_config
    
    base = f"Asistente de {tenant.brand_name}"
    
    # Cada cliente tiene su propio tono
    tone = {
        "bank_corp": "Formal, preciso, cita regulaciones",
        "startup_ai": "Casual, innovador, usa ejemplos tech",
        "medical_center": "EmpÃ¡tico, claro, evita jerga"
    }[tenant.tenant_id]
    
    # Cada cliente tiene sus propias polÃ­ticas
    policies = tenant.get_policies()  # Desde DB
    
    return f"{base}\n\nTono: {tone}\n\nPolÃ­ticas:\n{policies}"
```

**Beneficios en producciÃ³n:**
- âœ… **Seguridad**: RBAC a nivel de LLM
- âœ… **PersonalizaciÃ³n**: Experiencia adaptada al usuario
- âœ… **Compliance**: Restricciones temporales automÃ¡ticas
- âœ… **Escalabilidad**: Un agente sirve mÃºltiples casos de uso

---

## 7. Ejercicios prÃ¡cticos

Es hora de aplicar lo aprendido. Estos ejercicios cubren los patrones avanzados del mÃ³dulo en contextos empresariales reales.

### Ejercicio 1: Tool de cÃ¡lculo de comisiones con validaciÃ³n

**Archivo:** `01-agentes-avanzados/ej01_comisiones.py`  
**Tiempo estimado:** 25 minutos

**Contexto empresarial:**  
Eres el desarrollador de un sistema de compensaciones para el equipo de ventas. Necesitas un agente que calcule comisiones segÃºn el tier del vendedor, pero con validaciÃ³n estricta para evitar pagos errÃ³neos.

**Objetivo:** Crea un agente que calcule comisiones de ventas con:
- Tool `calculate_commission(sales_amount: float, tier: str)` donde tier âˆˆ {bronze, silver, gold}
- Tasas de comisiÃ³n: Bronze 3%, Silver 5%, Gold 8%
- Result validator que verifique que las comisiones no excedan 10,000 EUR
- Si exceden, debe lanzar `ModelRetry` sugiriendo revisar el tier

**Schema del output:**
```python
class CommissionResult(BaseModel):
    sales_amount_eur: float
    tier: str
    commission_rate: float  # Como decimal (0.03, 0.05, 0.08)
    commission_eur: float
    approved: bool
```

**Criterio de Ã©xito:**
- âœ… La tool valida el tier con `Literal["bronze", "silver", "gold"]`
- âœ… El validator detecta comisiones > 10k y fuerza retry con feedback especÃ­fico
- âœ… El agente responde con el `CommissionResult` estructurado
- âœ… Prueba con: 80k EUR Gold (deberÃ­a aprobar), 150k EUR Gold (deberÃ­a pedir revisar tier)

**Pista:** Usa `@agent.result_validator` para verificar `commission_eur > 10000`.

---

### Ejercicio 2: Reflection para generaciÃ³n de metadescripciones SEO

**Archivo:** `01-agentes-avanzados/ej02_seo_reflection.py`  
**Tiempo estimado:** 30 minutos

**Contexto empresarial:**  
Trabajas en una agencia de marketing digital que genera cientos de metadescripciones para sitios web de clientes. Necesitas automatizar la generaciÃ³n con garantÃ­a de calidad SEO.

**Objetivo:** Agente que genera metadescripciones con reflection automÃ¡tico:

**Schema del output:**
```python
class MetaDescription(BaseModel):
    text: str = Field(min_length=140, max_length=160)
    char_count: int
    keyword_density: float  # Veces que aparece keyword / total palabras
```

**Validaciones del reflection (en `@agent.result_validator`):**
1. Longitud: 140-160 caracteres (Ã³ptimo para Google)
2. Debe contener la keyword principal al menos 1 vez
3. No debe contener palabras genÃ©ricas prohibidas: "increÃ­ble", "mejor", "Ãºnico", "revolucionario"
4. El tono debe ser profesional (no clickbait)

**Criterio de Ã©xito:**
- âœ… Si la descripciÃ³n no cumple, el validator da feedback especÃ­fico sobre QUÃ‰ falla
- âœ… El agente reescribe hasta cumplir todos los criterios o agotar 3 retries
- âœ… Prueba con keyword: "zapatos deportivos" y pÃ¡gina: "tienda online de running"
- âœ… Imprime el nÃºmero de intentos usados

**Pista:** Para contar palabras: `len(text.split())`. Para calcular keyword_density: `text.lower().count(keyword) / len(text.split())`.

---

### Ejercicio 3: Multi-tool con orquestaciÃ³n de inventario y pedidos

**Archivo:** `01-agentes-avanzados/ej03_multi_tool_warehouse.py`  
**Tiempo estimado:** 35 minutos

**Contexto empresarial:**  
Construyes un sistema de gestiÃ³n de almacÃ©n para una empresa de e-commerce. El agente debe poder consultar stock, reservar unidades y estimar entregas, decidiendo automÃ¡ticamente quÃ© operaciones realizar segÃºn la consulta del usuario.

**Objetivo:** Sistema de gestiÃ³n de almacÃ©n con 3 tools que el agente orquesta:

1. `check_stock(product_code: str) -> dict`
   - Consulta stock disponible y precio
   - Devuelve: {product_code, name, stock_units, price_eur, available}

2. `reserve_stock(product_code: str, quantity: int) -> dict`
   - Reserva unidades (solo si hay stock suficiente)
   - Devuelve: {reserved, quantity, remaining_stock}

3. `estimate_delivery(product_code: str, destination: str) -> dict`
   - Estima tiempo de entrega segÃºn destino
   - Destination âˆˆ {local, national, international}
   - Devuelve: {estimated_days, shipping_cost_eur}

**Base de datos mock:**
```python
WAREHOUSE = {
    "PROD-001": {"name": "Laptop Pro", "stock": 5, "price": 1299},
    "PROD-002": {"name": "Mouse", "stock": 0, "price": 29},
    "PROD-003": {"name": "Monitor", "stock": 15, "price": 449},
}
```

**Criterio de Ã©xito:**
- âœ… El agente verifica stock ANTES de intentar reservar
- âœ… Si no hay stock, informa sin llamar `reserve_stock`
- âœ… Tras reserva exitosa, automÃ¡ticamente estima entrega
- âœ… Prueba: "Quiero 3 Laptop Pro para envÃ­o nacional" (deberÃ­a verificar â†’ reservar â†’ estimar)
- âœ… Prueba: "Â¿Hay Mouse disponible?" (deberÃ­a solo verificar y decir que estÃ¡ agotado)

**Pista:** El agente decide automÃ¡ticamente el flujo. Tu trabajo es implementar las tools correctamente y dejar que el LLM orqueste.

---

### Ejercicio 4: Tool con deps para acceso a API externa

**Archivo:** `01-agentes-avanzados/ej04_tool_api_deps.py`  
**Tiempo estimado:** 30 minutos

**Contexto empresarial:**  
Integras un agente con una API de tipos de cambio para un dashboard financiero. Necesitas diseÃ±ar la arquitectura para que el cÃ³digo sea testeable y el API key estÃ© controlado.

**Objetivo:** Agente que consulta tipos de cambio usando dependency injection:

**Definir deps:**
```python
@dataclass
class CurrencyAPIDeps:
    api_key: str
    base_url: str
```

**Tool:**
```python
@agent.tool
async def get_exchange_rate(
    ctx: RunContext[CurrencyAPIDeps],
    from_currency: str,
    to_currency: str
) -> dict:
    """
    Obtiene el tipo de cambio entre dos divisas.
    
    Usa ctx.deps.api_key y ctx.deps.base_url para simular
    una llamada a API externa (no hace request real en este ejercicio).
    """
    # Simular respuesta de API
    rates = {
        ("EUR", "USD"): 1.09,
        ("USD", "EUR"): 0.92,
        ("EUR", "GBP"): 0.86,
        ("GBP", "EUR"): 1.17,
        # ... etc
    }
    rate = rates.get((from_currency, to_currency))
    if not rate:
        raise ModelRetry(f"ConversiÃ³n {from_currency}->{to_currency} no disponible")
    
    return {
        "from": from_currency,
        "to": to_currency,
        "rate": rate,
        "api_used": ctx.deps.base_url  # Para demostrar que accede a deps
    }
```

**Criterio de Ã©xito:**
- âœ… La tool recibe deps a travÃ©s de `RunContext[CurrencyAPIDeps]`
- âœ… El agente responde preguntas tipo "Â¿CuÃ¡ntos dÃ³lares son 100 euros?"
- âœ… El cÃ³digo muestra cÃ³mo podrÃ­as reemplazar la simulaciÃ³n con una llamada real
- âœ… Incluye un comentario explicando cÃ³mo harÃ­as testing con un mock

**Pista:** En producciÃ³n harÃ­as: `response = requests.get(f"{ctx.deps.base_url}/rates", headers={"API-Key": ctx.deps.api_key})`.

---

### Ejercicio 5: Error handling completo con fallback

**Archivo:** `01-agentes-avanzados/ej05_error_handling_completo.py`  
**Tiempo estimado:** 35 minutos

**Contexto empresarial:**  
Desarrollas un chatbot de atenciÃ³n al cliente que debe NUNCA mostrar errores tÃ©cnicos al usuario. Todo fallo debe manejarse elegantemente con mensajes profesionales y escalaciÃ³n cuando sea necesario.

**Objetivo:** Agente de atenciÃ³n al cliente con manejo robusto de errores:

**Schema del output:**
```python
class CustomerResponse(BaseModel):
    message: str  # Respuesta al cliente
    ticket_id: str | None = None  # ID de ticket si se creÃ³
    escalated: bool  # Si se escalÃ³ a humano
```

**Implementar funciÃ³n wrapper:**
```python
def handle_customer_query(query: str) -> dict:
    """
    Maneja consulta con 3 niveles de error catching.
    
    Returns siempre un dict estructurado, nunca lanza excepciones.
    """
    try:
        result = agent.run_sync(query)
        return {
            "status": "success",
            "response": result.output.model_dump()
        }
    except ModelRetry as e:
        # AgotÃ³ retries: escalar a humano
        return {
            "status": "escalated",
            "response": CustomerResponse(
                message="He transferido tu consulta a un agente humano que te contactarÃ¡ pronto.",
                ticket_id=f"TKT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                escalated=True
            ).model_dump()
        }
    except UnexpectedModelBehavior as e:
        # Comportamiento raro del modelo
        return {
            "status": "error",
            "response": CustomerResponse(
                message="Disculpa, estoy experimentando dificultades tÃ©cnicas. Un supervisor revisarÃ¡ tu caso.",
                ticket_id=f"ERR-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                escalated=True
            ).model_dump(),
            "internal_error": "UMB",
            "support_code": "ERR-UMB-001"
        }
    except Exception as e:
        # Error genÃ©rico (red, API, etc.)
        return {
            "status": "system_error",
            "response": CustomerResponse(
                message="Lo sentimos, estamos experimentando problemas tÃ©cnicos. Por favor, reintenta en unos minutos.",
                ticket_id=f"SYS-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                escalated=False
            ).model_dump(),
            "support_code": "ERR-SYS-001"
        }
```

**Criterio de Ã©xito:**
- âœ… Maneja 3 tipos de error diferentes con mensajes especÃ­ficos
- âœ… Nunca expone errores tÃ©cnicos al usuario (stack traces, nombres de excepciones)
- âœ… Incluye cÃ³digos de error Ãºnicos para que soporte pueda buscar en logs
- âœ… Genera ticket_id en caso de escalaciÃ³n
- âœ… Prueba: consulta normal, consulta que causa retry, consulta con API key invÃ¡lida

---

### Ejercicio 6: Reflection + retries diferenciados

**Archivo:** `01-agentes-avanzados/ej06_reflection_retries.py`  
**Tiempo estimado:** 40 minutos

**Contexto empresarial:**  
Generas reportes ejecutivos automÃ¡ticos para CEOs. Estos reportes deben ser impecables: tono profesional, mÃ©tricas claras, recomendaciones accionables. UsarÃ¡s reflection avanzado con configuraciÃ³n de retries optimizada.

**Objetivo:** Agente que genera reportes ejecutivos con reflection y retries configurados:

**Schema del output:**
```python
class ExecutiveReport(BaseModel):
    title: str = Field(max_length=80)
    summary: str = Field(min_length=100, max_length=250)  # Palabras, no chars
    key_metrics: list[str] = Field(min_length=3, max_length=5)
    recommendations: list[str] = Field(min_length=2, max_length=4)
```

**ConfiguraciÃ³n:**
```python
agent = Agent(
    model,
    output_type=ExecutiveReport,
    retries=2,         # Para errores de tools
    output_retries=4   # Para validaciÃ³n del output
)
```

**Result validator que verifica:**
1. **Title** < 80 caracteres
2. **Summary** entre 100-250 PALABRAS (no caracteres)
3. Al menos **3 key_metrics** especÃ­ficas (no vagas tipo "mejora general")
4. Cada **recommendation** debe ser accionable (contener un verbo de acciÃ³n: "implementar", "reducir", "contratar", etc.)

**Criterio de Ã©xito:**
- âœ… El validator da feedback especÃ­fico para cada criterio no cumplido
- âœ… El agente itera hasta cumplir todos o agotar los 4 output_retries
- âœ… Imprime el nÃºmero total de intentos usados: `result.all_messages_count`
- âœ… Prueba con: "Genera reporte Q4 2024: ventas +15%, costes -8%, NPS 72"
- âœ… El reporte final debe pasar TODAS las validaciones

**Pista para validar verbos de acciÃ³n:**
```python
action_verbs = {"implementar", "reducir", "aumentar", "contratar", "optimizar", 
                "desarrollar", "lanzar", "eliminar", "priorizar", "invertir"}
has_action = any(verb in rec.lower() for verb in action_verbs)
```

---

## 8. Troubleshooting y mejores prÃ¡cticas

Esta secciÃ³n recopila problemas comunes que encontrarÃ¡s al desarrollar agentes avanzados y cÃ³mo resolverlos.

### Errores comunes y soluciones

| SÃ­ntoma | Causa probable | SoluciÃ³n |
|---------|---------------|----------|
| **`ModelRetry` sin mensaje Ãºtil** | Lanzas `ModelRetry()` vacÃ­o | Siempre incluye mensaje especÃ­fico: `ModelRetry("El campo X debe ser Y porque Z")` |
| **Retries infinitos / timeout** | Validator demasiado estricto | AÃ±ade logging en el validator para ver quÃ© falla. Revisa si tus criterios son realistas |
| **Tool nunca se llama** | Docstring poco claro o confuso | El LLM decide basÃ¡ndose en el docstring. Hazlo mÃ¡s especÃ­fico con ejemplos de cuÃ¡ndo usarla |
| **Tool muy lenta** | Operaciones sÃ­ncronas bloqueantes (DB, API) | Usa `async def` y `await` correctamente para operaciones I/O |
| **ValidationError inesperado** | Schema del output demasiado restrictivo | Empieza simple y aÃ±ade validaciones gradualmente. Prueba el schema manualmente primero |
| **Agente ignora instrucciones dinÃ¡micas** | `@agent.instructions` no devuelve string | Verifica que tu funciÃ³n retorna un `str`, no None o un objeto |
| **Deps no llegan a la tool** | Olvidaste pasar `deps` en `run_sync()` | Siempre: `agent.run_sync(query, deps=my_deps)` |
| **"Cannot pickle..." en tools async** | Usas objetos no serializables en deps | Usa dataclasses simples en deps, no objetos complejos con estado |

### Best practices de desarrollo

#### 1. Desarrollo iterativo de validators

No escribas validaciones complejas desde el principio. Empieza simple:

```python
# âŒ Mal: validador complejo desde el inicio
@agent.result_validator
async def validate(ctx, result):
    # 20 lÃ­neas de validaciones anidadas
    ...

# âœ… Bien: empieza simple, aÃ±ade complejidad gradualmente
@agent.result_validator
async def validate_v1(ctx, result):
    # Solo valida longitud
    if len(result.text) > 280:
        raise ModelRetry("MÃ¡ximo 280 caracteres")
    return result

# Luego aÃ±ades mÃ¡s validaciones una por una
@agent.result_validator
async def validate_v2(ctx, result):
    if len(result.text) > 280:
        raise ModelRetry("MÃ¡ximo 280 caracteres")
    
    # Nueva validaciÃ³n
    if not result.text[0].isupper():
        raise ModelRetry("La primera letra debe ser mayÃºscula")
    
    return result
```

#### 2. Logging estratÃ©gico

En producciÃ³n necesitas entender quÃ© estÃ¡ pasando. AÃ±ade logs en puntos clave:

```python
@agent.result_validator
async def validate(ctx, result):
    logger.info(f"Validando resultado: {result.model_dump()}")
    
    if result.score < 50:
        logger.warning(f"Score bajo: {result.score}, forzando retry")
        raise ModelRetry("Score debe ser â‰¥ 50")
    
    logger.info("ValidaciÃ³n exitosa")
    return result

@agent.tool
async def critical_operation(ctx, amount):
    logger.info(f"[{ctx.deps.user_id}] Ejecutando operaciÃ³n crÃ­tica: {amount} EUR")
    
    try:
        result = process_payment(amount)
        logger.info(f"OperaciÃ³n exitosa: {result}")
        return result
    except Exception as e:
        logger.error(f"FallÃ³ operaciÃ³n: {e}", exc_info=True)
        raise
```

#### 3. Testing de tools

Las tools deben ser testeables independientemente del agente:

```python
# Tool
@agent.tool
async def calculate_tax(ctx: RunContext[None], amount: float) -> dict:
    """Calcula IVA 21%."""
    return {
        "amount": amount,
        "tax": round(amount * 0.21, 2),
        "total": round(amount * 1.21, 2)
    }

# Test (puedes usar pytest)
def test_calculate_tax():
    # Crea un contexto mock
    mock_ctx = MagicMock(spec=RunContext)
    mock_ctx.deps = None
    
    # Llama la tool directamente
    result = asyncio.run(calculate_tax(mock_ctx, 100.0))
    
    assert result["tax"] == 21.0
    assert result["total"] == 121.0
```

#### 4. ConfiguraciÃ³n de retries basada en criticidad

Establece una polÃ­tica clara:

```python
# Archivo: retry_policy.py
class RetryPolicy:
    """PolÃ­tica de reintentos segÃºn criticidad."""
    
    # Tools crÃ­ticas (afectan dinero, datos sensibles)
    CRITICAL = 5
    
    # Tools importantes (afectan experiencia de usuario)
    HIGH = 3
    
    # Tools normales (consultas, cÃ¡lculos)
    NORMAL = 2
    
    # Tools experimentales o informativas
    LOW = 1

# Uso
@agent.tool(retries=RetryPolicy.CRITICAL)
async def process_payment(...):
    pass

@agent.tool(retries=RetryPolicy.LOW)
async def get_weather(...):
    pass
```

#### 5. Docstrings efectivos para tools

El LLM decide cuÃ¡ndo usar una tool basÃ¡ndose en su docstring. Hazlos especÃ­ficos:

```python
# âŒ Mal: docstring vago
@agent.tool
def get_data(ctx, id: int):
    """Gets data."""
    pass

# âœ… Bien: docstring descriptivo
@agent.tool
def get_employee_salary(ctx, employee_id: int) -> dict:
    """
    Obtiene el salario actual de un empleado por su ID.
    
    Ãšsala cuando el usuario pregunte sobre:
    - CuÃ¡nto gana un empleado
    - El salario de una persona
    - CompensaciÃ³n de un miembro del equipo
    
    NO la uses para:
    - Salario promedio del departamento (usa get_department_stats)
    - Historial de salarios (usa get_salary_history)
    
    Args:
        employee_id: ID numÃ©rico del empleado (ej: 101, 102).
        
    Returns:
        Dict con 'employee_id', 'name', 'salary_eur' y 'currency'.
    """
    pass
```

#### 6. Manejo de deps complejas

Si tus deps son complejas, crea una factory:

```python
# âŒ Mal: crear deps manualmente cada vez
db = create_db_connection()
cache = create_cache_client()
logger = setup_logger()
deps = AppDeps(db=db, cache=cache, logger=logger, user=user, ...)

# âœ… Bien: factory que centraliza la lÃ³gica
class DepsFactory:
    @staticmethod
    def create_for_user(user: User) -> AppDeps:
        return AppDeps(
            db=get_db_connection(),
            cache=get_cache_client(),
            logger=get_logger(),
            user=user,
            request_id=generate_request_id(),
            config=load_config()
        )

# Uso limpio
deps = DepsFactory.create_for_user(current_user)
result = agent.run_sync(query, deps=deps)
```

---

## 9. Caso de uso: EvoluciÃ³n del DataPulse AI

Ahora que dominas las tÃ©cnicas avanzadas, vamos a evolucionar el DataPulse AI del MÃ³dulo 0 en un sistema robusto de producciÃ³n.

### Mejoras implementadas en v2

**ComparaciÃ³n MÃ³dulo 0 vs MÃ³dulo 1:**

| Aspecto | MÃ³dulo 0 (BÃ¡sico) | MÃ³dulo 1 (Avanzado) |
|---------|-------------------|---------------------|
| **ValidaciÃ³n** | Solo Pydantic bÃ¡sico | Result validator + reflection |
| **Manejo de errores** | `try/except` simple | Captura diferenciada por tipo |
| **Calidad del output** | Sin garantÃ­as | AutocorrecciÃ³n automÃ¡tica |
| **Retries** | ConfiguraciÃ³n global | Diferenciados por criticidad |
| **MÃ©tricas** | Texto libre | Estructuradas y verificadas |

**`01-agentes-avanzados/datapulse_v2.py`:**

```python
from typing import Literal
from pydantic import BaseModel, Field, field_validator
from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings

class BusinessInsight(BaseModel):
    """Respuesta estructurada con insight empresarial validado."""
    intencion: Literal["resumen", "comparativa", "forecast"]
    respuesta: str = Field(min_length=50, max_length=300)
    metricas_clave: list[str] = Field(min_length=2, max_length=4)
    nivel_confianza: float = Field(ge=0, le=1, description="0-1")
    requiere_accion: bool = Field(description="Si requiere acciÃ³n del usuario")

model = OpenAIChatModel(
    "gpt-5",
    provider=OpenAIProvider(api_key=settings.openai_api_key)
)

agent = Agent(
    model,
    output_type=BusinessInsight,
    retries=2,          # Para errores generales
    output_retries=3,   # Para validaciÃ³n del output
    instructions=(
        "Eres DataPulse AI, asistente de anÃ¡lisis empresarial para PYMEs. "
        "Proporcionas insights claros, breves y accionables sobre datos de negocio. "
        "Tu lenguaje es profesional pero accesible."
    )
)

@agent.result_validator
async def validate_business_insight_quality(
    ctx: RunContext[None],
    result: BusinessInsight
) -> BusinessInsight:
    """
    Valida que el insight cumpla estÃ¡ndares de calidad empresarial.
    
    Este validator implementa reflection: actÃºa como un editor de
    contenido que revisa el trabajo del agente y lo mejora iterativamente.
    """
    issues = []
    
    # ValidaciÃ³n 1: Evitar lenguaje genÃ©rico tipo brochure
    generic_words = ["bien", "normal", "estable", "interesante"]
    if any(word in result.respuesta.lower() for word in generic_words):
        issues.append(
            "La respuesta contiene tÃ©rminos genÃ©ricos. "
            "Usa datos especÃ­ficos y lenguaje ejecutivo."
        )
    
    # ValidaciÃ³n 2: MÃ©tricas deben ser especÃ­ficas y medibles
    for metric in result.metricas_clave:
        # Una mÃ©trica debe tener al menos 3 palabras (ej: "Crecimiento Q3: +15%")
        if len(metric.split()) < 3:
            issues.append(
                f"La mÃ©trica '{metric}' es demasiado vaga. "
                "Usa formato: 'Nombre mÃ©trica: valor unidad' (ej: 'Crecimiento ventas: +15%')."
            )
        
        # Debe contener algÃºn nÃºmero o porcentaje
        if not any(char.isdigit() for char in metric):
            issues.append(
                f"La mÃ©trica '{metric}' no incluye valores numÃ©ricos. "
                "Incluye el dato concreto."
            )
    
    # ValidaciÃ³n 3: Coherencia entre confianza y acciÃ³n requerida
    if result.nivel_confianza < 0.6 and result.requiere_accion:
        issues.append(
            f"Confianza baja ({result.nivel_confianza:.0%}) pero marcado como 'requiere acciÃ³n'. "
            "Si la confianza es <60%, no deberÃ­a requerir acciÃ³n inmediata. "
            "Marca como no requiere acciÃ³n o incrementa la confianza justificadamente."
        )
    
    # Si hay problemas, forzar reescritura con feedback consolidado
    if issues:
        feedback = "\n".join(f"â€¢ {issue}" for issue in issues)
        raise ModelRetry(
            f"El insight necesita mejoras:\n{feedback}\n\n"
            "Regenera el insight corrigiendo estos aspectos especÃ­ficos."
        )
    
    return result

# FunciÃ³n wrapper con manejo de errores robusto
def get_business_insight(query: str) -> dict:
    """
    Obtiene insight con manejo completo de errores.
    
    Returns:
        Dict estructurado que siempre tiene 'status' y contenido relevante.
    """
    try:
        result = agent.run_sync(query)
        insight = result.output
        
        return {
            "status": "success",
            "insight": insight.model_dump(),
            "attempts": len(result.all_messages()),
            "tokens_used": result.usage().total_tokens if result.usage() else 0
        }
        
    except ModelRetry as e:
        return {
            "status": "error",
            "error_type": "max_retries",
            "message": "No se pudo generar un insight que cumpla los estÃ¡ndares de calidad.",
            "suggestion": "Reformula la pregunta con mÃ¡s contexto o datos especÃ­ficos."
        }
    
    except Exception as e:
        return {
            "status": "system_error",
            "message": "Error del sistema. Contacta con soporte.",
            "support_code": "ERR-DP-001"
        }

# Pruebas del DataPulse AI v2
test_queries = [
    "ResÃºmeme las ventas de este trimestre",
    "Â¿CÃ³mo van las ventas de este mes comparadas con el mes pasado?",
    "Â¿QuÃ© tendencias esperas para el prÃ³ximo trimestre?"
]

print("=" * 70)
print("DATAPULSE AI v2 - AGENTE AVANZADO")
print("=" * 70)

for query in test_queries:
    print(f"\n{'â”€' * 70}")
    print(f"ğŸ“Š Consulta: {query}")
    print('â”€' * 70)
    
    response = get_business_insight(query)
    
    if response["status"] == "success":
        insight = response["insight"]
        
        print(f"\nâœ“ IntenciÃ³n: {insight['intencion'].upper()}")
        print(f"âœ“ Confianza: {insight['nivel_confianza']:.0%}")
        print(f"âœ“ Requiere acciÃ³n: {'SÃ­' if insight['requiere_accion'] else 'No'}")
        
        print(f"\nğŸ“ Respuesta:\n{insight['respuesta']}")
        
        print(f"\nğŸ“ˆ MÃ©tricas clave:")
        for metric in insight['metricas_clave']:
            print(f"  â€¢ {metric}")
        
        print(f"\nğŸ”§ Intentos: {response['attempts']} | Tokens: {response['tokens_used']}")
    
    else:
        print(f"\nâŒ Error: {response['message']}")
        if "suggestion" in response:
            print(f"ğŸ’¡ Sugerencia: {response['suggestion']}")

print(f"\n{'=' * 70}\n")
```

**Ejecuta la versiÃ³n avanzada:**
```bash
uv run python 01-agentes-avanzados/datapulse_v2.py
```

**Â¿QuÃ© mejoras notarÃ¡s?**

1. **AutocorrecciÃ³n automÃ¡tica**: Si el agente genera mÃ©tricas vagas tipo "Ventas buenas", el validator lo detecta y fuerza reescritura

2. **MÃ©tricas estructuradas**: Ya no acepta texto libre. Cada mÃ©trica debe tener formato especÃ­fico con valores numÃ©ricos

3. **Coherencia lÃ³gica**: Verifica que la confianza y la necesidad de acciÃ³n sean coherentes entre sÃ­

4. **Manejo de errores profesional**: Nunca verÃ¡s un stack trace, solo mensajes estructurados con cÃ³digos de soporte

5. **Observabilidad**: Puedes ver cuÃ¡ntos intentos usÃ³ y cuÃ¡ntos tokens consumiÃ³

**ComparaciÃ³n de outputs:**

```
MÃ³dulo 0:
{
  "respuesta": "Las ventas estÃ¡n bien este trimestre."
}

MÃ³dulo 1 (tras reflection):
{
  "respuesta": "Q3 registrÃ³ 145k EUR en ventas (+12% vs Q2). El segmento Premium liderÃ³ con 35% del total.",
  "metricas_clave": [
    "Ventas Q3: 145,000 EUR",
    "Crecimiento interanual: +12%",
    "ParticipaciÃ³n Premium: 35%"
  ],
  "nivel_confianza": 0.85,
  "requiere_accion": false
}
```

---

## 10. PrÃ³ximos pasos

**Â¡Felicidades por completar el MÃ³dulo 1!** Ahora sabes construir agentes robustos con validaciÃ³n, autocorrecciÃ³n, manejo de errores y dependencias.

**Habilidades adquiridas:**
- âœ… Tools complejas con validaciÃ³n Pydantic de parÃ¡metros
- âœ… Result validators que garantizan calidad del output
- âœ… Reflection patterns para mejora iterativa automÃ¡tica
- âœ… ConfiguraciÃ³n inteligente de retries por criticidad
- âœ… OrquestaciÃ³n de mÃºltiples tools
- âœ… Dependency injection para integraciÃ³n con sistemas externos
- âœ… Manejo de errores profesional con fallbacks
- âœ… Instrucciones dinÃ¡micas basadas en contexto

**En el MÃ³dulo 2 aprenderÃ¡s:**
- **GestiÃ³n de contexto conversacional**: Mantener estado entre mÃºltiples mensajes
- **Streaming avanzado**: Respuestas progresivas para mejor UX
- **IntegraciÃ³n con datos reales**: Conectar con CSV, bases de datos y APIs
- **Sesiones y persistencia**: Guardar y recuperar conversaciones

**En el MÃ³dulo 3 construirÃ¡s:**
- **Agentes jerÃ¡rquicos**: Agentes que delegan subtareas a otros agentes
- **Workflows complejos**: Encadenamiento de mÃºltiples agentes
- **IntegraciÃ³n con herramientas externas**: BÃºsqueda web, generaciÃ³n de grÃ¡ficos
- **Despliegue en producciÃ³n**: Docker, APIs REST, Gradio

ContinÃºa con el [MÃ³dulo 2: Contexto y ValidaciÃ³n](../02-contexto-validacion/README.md) cuando estÃ©s listo.

---

## Referencias

DocumentaciÃ³n oficial que complementa este mÃ³dulo:

- [PydanticAI Agents](https://ai.pydantic.dev/agents/) - GuÃ­a completa de agentes
- [PydanticAI Tools](https://ai.pydantic.dev/tools/) - DocumentaciÃ³n de tools y parÃ¡metros
- [PydanticAI Output Validation](https://ai.pydantic.dev/output/) - ValidaciÃ³n de salidas
- [PydanticAI Retries](https://ai.pydantic.dev/retries/) - ConfiguraciÃ³n de reintentos
- [Pydantic Validators](https://docs.pydantic.dev/latest/concepts/validators/) - Validators custom

---

**Â© 2025 Alfons Freixes | PydanticAI Course**